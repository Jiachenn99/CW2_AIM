{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","celltoolbar":"Attachments","colab":{"name":"Better ver of CW1? ","provenance":[{"file_id":"1_QighMAVHkdl82Zm_7iQ9wUV6lF9vTP5","timestamp":1586070495413}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kgzFFe0fWjGL"},"source":["# Imports, Initialization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8o89uxX4xG1G","outputId":"c64db94b-e466-40d6-8f98-b08f88ef2c16","executionInfo":{"status":"ok","timestamp":1586243667413,"user_tz":-480,"elapsed":8475,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["#@title\n","from __future__ import print_function\n","version = '_v0p3p9_'\n","\n","import time\n","import warnings\n","import csv\n","\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.mlab as mlab\n","import math\n","import scipy\n","import pytz \n","\n","from datetime import datetime, timezone,timedelta\n","from numpy import asarray\n","from numpy import savetxt\n","from numpy import genfromtxt\n","\n","from sklearn import cluster, datasets, mixture\n","from sklearn.neighbors import kneighbors_graph\n","from sklearn.preprocessing import StandardScaler\n","from itertools import cycle, islice\n","from tqdm import tqdm \n","\n","import torch\n","import numpy as np\n","from torch.utils import data\n","import copy\n","\n","import argparse\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","\n","from IPython.core.debugger import set_trace\n","\n","from google.colab import drive,files,output\n","# ===============\n","# Initializations\n","# ===============\n","\n","!pip install torch torchvision\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4Jqi0TGLXNLi"},"source":["# Declaring Framework Parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HFxR7S6TXM5o","colab":{}},"source":["# ===============\n","# Parameters\n","# ===============\n","\n","# --- General framework arguments\n","\n","args = {}\n","kwargs = {}\n","args['num_train_batch'] = 1  # number of MNIST training batches\n","args['num_valid_batch'] = 10  # number of MNIST validation batches\n","args['train_batch_size'] = 100   # training batch size\n","args['valid_batch_size'] = 100   # validation batch size\n","args['test_batch_size'] = 10\n","# args['epochs'] = 100  # number of training epochs \n","args['lr'] = 1 # 0.1  # 0.01 # learning rate # this is over-written by the solution\n","args['momentum'] = 0.5 # SGD momentum (default: 0.5); momentum is a moving average of our gradients (helps keep a useful direction)\n","args['clip_level'] = 0.5  # gradient clip threshold\n","args['seed']= 1 #random seed\n","args['log_interval_epoch'] = 1 # display training loss every log_int... epochs\n","args['cuda'] = True \n","args['patience'] = 1000  # stop train. if the valid. err. hasn't improved by this num. of epochs\n","args['noise_in'] = -1   # 0.5  # 0.15  # amount of noise to add to the training data\n","args['noise_out'] = -1   #  probability of changing an output label to some random label\n","args['verbose_train'] = False   # print status of model training?\n","args['verbose_meta'] = True #  print status of architecture optimization?\n","args['min_inst_class'] = 5 # minimum number of instances per class in the training set\n","args['batch_max_tries'] = 10 # max. num. of attempts in extracting data batches\n","args['save_best_chrom'] = True # False  # save the best chromose in Google Drive?\n","args['dc_prob_drop'] = 0.5 # 0.5 # probability of dropping a circuit (DropCircuit)\n","args['prob_sel_branch'] = 0.5 # probability of architectural search selecting/using a branch (this is not DropCircuit) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WHRtBqQPXUgZ"},"source":["# Declaring Neural Network Architecture Parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OFe4d-SEXW0f","colab":{}},"source":["# --- Neural architectural limits\n","\n","args['num_epochs_search'] = 10 # 100  # number of epochs for training during architecture search \n","args['num_epochs_test'] = 1000  # num. epochs for training during the final test\n","limits = {}\n","limits['min_layer_nodes'] =  10 # 5 # 50\n","limits['max_layer_nodes'] = 100\n","limits['max_pre_branch_layers'] = 5 # 3\n","limits['max_branches'] = 10\n","limits['max_branch_layers'] = 5  # 3\n","limits['max_post_branch_layers'] = 5 # 3\n","limits['lr1_min'] = 0.001\n","limits['lr1_,max'] = 2\n","limits['lr2_min'] = 0.001\n","limits['lr2_,max'] = 2\n","limits['moment_min'] = 0.001\n","limits['moment_max'] = 1\n","\n","# np.random.seed(0)\n","# torch.manual_seed(0)\n","\n","num_train_instances = args['num_train_batch'] * args['train_batch_size']\n","num_valid_instances = args['num_valid_batch'] * args['valid_batch_size']\n","\n","data_rand_seed = 1 # (other pre-tested seeds: 2, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9pz5Mgv6X3mT"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"t3H0b-IqX4yu","colab":{}},"source":["# ============\n","# Load dataset\n","# ============\n","\n","# Function to be added here to load dataset\n","def load_from_csv(path):\n","    '''\n","    Loads the csv file from path specified into a np array\n","\n","    Args:\n","    path: Path where file is located\n","    e.g path='gdrive/My Drive/Chromosome Saves/chrom_acc72'\n","\n","    Returns:\n","    None\n","    '''\n","    drive.mount('/content/gdrive/')\n","    some_file = np.genfromtxt(path, dtype='float', delimiter=',')\n","\n","    return some_file\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O6Jaw59JYa8Z"},"source":["# Seed Creation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"35Ewp2u7X97m","colab":{}},"source":["# Seed creation\n","torch.manual_seed(data_rand_seed)\n","np.random.seed(data_rand_seed)\n","\n","a_data_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n","  \n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=a_data_transform),\n","    batch_size=args['train_batch_size'], shuffle=True, **kwargs)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=a_data_transform),\n","    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P8OMy3wF1IIl"},"source":["# Classes\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yxbyQvvq1MDK","colab":{}},"source":["# Simple layer for doing elementwise scaling\n","# Adapated from https://stackoverflow.com/questions/51980654/pytorch-element-wise-filter-layer\n","class Elem_Scaling_1D(nn.Module):\n","  def __init__(self, num_nodes, bogus):  # clean-up \"bogus\"\n","    super(Elem_Scaling_1D, self).__init__()\n","    # Initialize\n","    init_weights = np.random.normal(loc=0, scale=0.5, size=np.shape(num_nodes))\n","    # Assign\n","    self.weights = torch.from_numpy(init_weights)\n","    #self.weights = nn.Parameter(torch.Tensor(1, num_nodes))  # trainable parameter\n","\n","  def forward(self, x):\n","    # assuming x is of size num_inst-1-num_nodes\n","    return x * self.weights  # element-wise multiplication\n","\n","# Class gradient-based neural diversity machine\n","class GBNDM(nn.Module):   \n","    def __init__(self, a_chromosome):   # assuming MNIST\n","        super(GBNDM, self).__init__()\n","\n","        # --------- Pre-branch layers \n","        self.chromosome = a_chromosome\n","        self.pre_branch_layers = nn.ModuleList()\n","        prev_num_out = 28*28\n","        chrom_ind = 5 # skip over 3 learning rate param., 1 moment. p. (interp./used in training)\n","        # and 1 exist-or-not (may use in future versions).\n","        # Each layer is [exist-or-not, id-or-linear, activation function (AF), 2 AF parameters, number of nodes → total: 6 parameters]\n","        for i in range(limits['max_pre_branch_layers']):\n","          \n","          # Extract and interpret parameters\n","          layer_params_raw = a_chromosome[chrom_ind:chrom_ind+6]\n","          layer_params_real = self.interp_layer_param(layer_params_raw)\n","        \n","          # Decide on whether to create a layer or not\n","          if i==0:  # the first layer of each segment is done by default\n","            do_layer = True\n","          else:\n","            do_layer = layer_params_real[0]\n","\n","          if do_layer:\n","            # Create layer    \n","            a_layer, prev_num_out = self.create_layer(prev_num_out, layer_params_real)\n","            # Append layer and update chromosome index\n","            self.pre_branch_layers.append(a_layer)\n","            \n","          chrom_ind += 6\n","\n","        # --------- Branches\n","        num_out_pre_branch = prev_num_out\n","\n","        self.branches = nn.ModuleList()\n","\n","        # Scan over branches\n","        final_num_nodes = []  # keep track of the size of the final layer of each branch\n","        count_branches = 0\n","        for bi in range(limits['max_branches']):\n","\n","          # Initialize branch\n","          branch_layers = nn.ModuleList()\n","\n","          # Do branch? Always do the first one by default\n","          if (a_chromosome[chrom_ind] < args['prob_sel_branch']) or (bi == 0):\n","            do_branch = True\n","          else: \n","            do_branch = False\n","            \n","          chrom_ind += 1\n","\n","          # Scan over branch layers\n","\n","          if do_branch:  # if doing branch\n","\n","            this_fin_num_nodes = 0\n","\n","            count_branches += 1\n","            \n","            for li in range(limits['max_branch_layers']):\n","\n","              # Extract and interpret parameters\n","              layer_params_raw = a_chromosome[chrom_ind:chrom_ind+6]\n","              layer_params_real = self.interp_layer_param(layer_params_raw)\n","\n","              # Decide on whether to create a layer or not\n","              if li==0:  # the first layer of each branch is done by default\n","                do_layer = True\n","                prev_num_out = num_out_pre_branch\n","              else:\n","                do_layer = layer_params_real[0]\n","\n","              if do_layer:\n","                # print('... temp ... this_fin_num_nodes: {}.'.format(this_fin_num_nodes))\n","                # Create layer    \n","                a_layer, prev_num_out = self.create_layer(prev_num_out, layer_params_real)\n","                # Num_nodes - keep storing the latest one; the last latest is the final layer num_nodes\n","                this_fin_num_nodes = prev_num_out\n","                # Append layer and update chromosome index\n","                branch_layers.append(a_layer)\n","\n","              chrom_ind += 6\n","\n","            # Append branch\n","            final_num_nodes.append(this_fin_num_nodes)\n","            #print('final_num_nodes: {}.'.format(final_num_nodes))\n","            self.branches.append(branch_layers)\n","\n","          else: # if not doing branch you still need to increment chromosome index\n","\n","            chrom_ind += 6*limits['max_branch_layers']\n","\n","        self.num_branches = count_branches\n","        self.dc_prob_activ = 1 - args['dc_prob_drop'] # probability of using a circuit\n","        self.tot_nodes_branch_final = sum(final_num_nodes)\n","        \n","        # --------- Post-branch layers\n","\n","        prev_num_out = self.tot_nodes_branch_final\n","        \n","        # --- Create post-branch layers\n","\n","        chrom_ind += 1  # skip over the parameter pertaining to the existence or not of the post-branch segment\n","\n","        self.post_branch_layers = nn.ModuleList()\n","        \n","        # Each layer is [exist-or-not, id-or-linear, activation function (AF), 2 AF parameters, number of nodes → total: 6 parameters]\n","        for li in range(limits['max_post_branch_layers']):\n","          \n","          # Extract and interpret parameters\n","          layer_params_raw = a_chromosome[chrom_ind:chrom_ind+6]\n","          layer_params_real = self.interp_layer_param(layer_params_raw)\n","        \n","          # Decide on whether to create a layer or not\n","          if li==0:  # the first layer of each segment is done by default\n","            do_layer = True\n","          else:\n","            do_layer = layer_params_real[0]\n","\n","          if do_layer:\n","            # Create layer    \n","            a_layer, prev_num_out = self.create_layer(prev_num_out, layer_params_real)\n","            # Append layer and update chromosome index\n","            self.post_branch_layers.append(a_layer)\n","            \n","          chrom_ind += 6\n","\n","        # Create a final layer\n","        self.final_layer = nn.Linear(prev_num_out, 10)\n","\n","    def forward(self, x, dc_mask = None):\n","        \n","        x = x.view(-1, 28*28)\n","\n","        # Apply pre-branch layers\n","        for pi, a_layer in enumerate(self.pre_branch_layers):\n","          #print('Pre-layer {}'.format(pi))\n","          # if isinstance(a_layer, Elem_Scaling_1D):\n","          #   set_trace()\n","          x = a_layer(x)\n","\n","        # Apply branches\n","        branch_finals = []\n","        for bi, a_branch in enumerate(self.branches):\n","          #print('Branch {}'.format(bi))\n","          \n","          z = x\n","\n","          for a_layer in a_branch:\n","            # if isinstance(a_layer, Elem_Scaling_1D):\n","            #   set_trace()\n","            z = a_layer(z)\n","          \n","          if self.training:\n","            z = (dc_mask[bi] * z) / self.dc_prob_activ  # if training apply DropCircuit\n","          \n","          branch_finals.append(z)\n","\n","        # Concatenate multi-branch final layers\n","        x = torch.cat(branch_finals,dim=1)\n","\n","        # if not(self.training): # if not training then testing/evaluating\n","        #   x = self.dc_prob_activ * x  # scaling due to DropCircuit\n","      \n","\n","        # Apply post-branch layers\n","        for pi, a_layer in enumerate(self.post_branch_layers):\n","          #print('Post-layer: {}'.format(pi))\n","          # if isinstance(a_layer, Elem_Scaling_1D):\n","          #   set_trace()\n","          x = a_layer(x)\n","\n","        # Apply final layer\n","        x = self.final_layer(x)\n","               \n","        return F.log_softmax(x, dim=1)\n","\n","\n","    # Method for interpreting layer parameters\n","    # Each layer is [exist-or-not, id-or-linear, activation function (AF), 2 AF parameters, number of nodes → total: 6 parameters]\n","    def interp_layer_param(self, layer_params_raw):\n","      # Exist or not\n","      if layer_params_raw[0] < 0.5:\n","        exist = False\n","      else:\n","        exist = True\n","      # Weight function\n","      tot_weight_func = 3\n","      if layer_params_raw[1] < 0.6: # or ... (1/tot_weight_func):  \n","        weight_func_sel = 'linear'\n","      elif layer_params_raw[1] < 0.8: # or ... (2/tot_weight_func):\n","        weight_func_sel = 'elem_scale'\n","      else:\n","        weight_func_sel = 'id'\n","      # activation function\n","      tot_node_func = 22\n","      if layer_params_raw[2] < (1/tot_node_func):\n","        activ_func = 'ReLU'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (2/tot_node_func):\n","        activ_func = 'Hardshrink'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = -1\n","      elif layer_params_raw[2] < (3/tot_node_func):\n","        activ_func = 'Hardtanh'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = scale_to_range(layer_params_raw[4],0,2)\n","        if param_1 > param_2:  # param_1 is min_val; param_2 is max_val\n","          tmp_val = param_1\n","          param_1 = param_2\n","          param_2 = tmp_val\n","        elif param_1 == param_2:\n","          param_2 += 0.1\n","      elif layer_params_raw[2] < (4/tot_node_func):\n","        activ_func = 'LeakyReLU'\n","        param_1 = scale_to_range(layer_params_raw[3],0,1)\n","        param_2 = -1\n","      elif layer_params_raw[2] < (5/tot_node_func):\n","        activ_func = 'LogSigmoid'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (6/tot_node_func):\n","        activ_func = 'PReLU'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (7/tot_node_func):\n","        activ_func = 'ELU'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = -1\n","      elif layer_params_raw[2] < (8/tot_node_func):\n","        activ_func = 'ReLU6'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (9/tot_node_func):\n","        activ_func = 'RReLU'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (10/tot_node_func):\n","        activ_func = 'SELU'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (11/tot_node_func):\n","        activ_func = 'CELU'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = -1\n","      elif layer_params_raw[2] < (12/tot_node_func):\n","        activ_func = 'GELU'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (13/tot_node_func):\n","        activ_func = 'Sigmoid'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (14/tot_node_func):\n","        activ_func = 'Softplus'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = scale_to_range(layer_params_raw[4],0,40)\n","      elif layer_params_raw[2] < (15/tot_node_func):\n","        activ_func = 'Softshrink'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = -1\n","      elif layer_params_raw[2] < (16/tot_node_func):\n","        activ_func = 'Softsign'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (17/tot_node_func):\n","        activ_func = 'Tanh'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (18/tot_node_func):\n","        activ_func = 'Tanhshrink'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (19/tot_node_func):\n","        activ_func = 'Threshold'\n","        param_1 = scale_to_range(layer_params_raw[3],0,2)\n","        param_2 = scale_to_range(layer_params_raw[4],0,2)\n","      elif layer_params_raw[2] < (20/tot_node_func):\n","        activ_func = 'Softmin'\n","        param_1 = -1\n","        param_2 = -1\n","      elif layer_params_raw[2] < (21/tot_node_func):\n","        activ_func = 'Softmax'\n","        param_1 = -1\n","        param_2 = -1\n","      else: \n","        activ_func = 'None'\n","        param_1 = -1\n","        param_2 = -1\n","\n","      # number of nodes\n","      num_nodes = scale_to_range(layer_params_raw[5], limits['min_layer_nodes'], limits['max_layer_nodes'])\n","      num_nodes = num_nodes.astype(int)\n","\n","      return (exist, weight_func_sel, activ_func, param_1, param_2, num_nodes)\n","\n","    # Method for creating a layer\n","    # layer_params_real format: (exist, weight_func_sel, activ_func, param_1, param_2, num_nodes)\n","    def create_layer(self, prev_num_out, layer_params_real):\n","      \n","      exist, weight_func_sel, activ_func, param_1, param_2, num_nodes = layer_params_real\n","      \n","      # wf_param1/wf_param2 --> not elegant \n","      if weight_func_sel == 'linear':\n","        weight_func = nn.Linear\n","        num_nodes_in = prev_num_out\n","        num_nodes_out = num_nodes\n","        wf_param1 = num_nodes_in\n","        wf_param2 = num_nodes_out\n","      elif weight_func_sel == 'id':\n","        weight_func = nn.Identity\n","        num_nodes_in = prev_num_out\n","        num_nodes_out = prev_num_out\n","        wf_param1 = num_nodes_in\n","        wf_param2 = num_nodes_out\n","      else:  # 'elem_scale'\n","        weight_func = Elem_Scaling_1D\n","        num_nodes_in = prev_num_out\n","        num_nodes_out = prev_num_out\n","        wf_param1 = num_nodes_in\n","        wf_param2 = num_nodes_out\n","        \n","      if activ_func == 'ReLU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.ReLU())\n","      elif activ_func == 'Hardshrink':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Hardshrink(param_1))\n","      elif activ_func == 'Hardtanh':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Hardtanh(param_1, param_2))\n","      elif activ_func == 'LeakyReLU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.LeakyReLU(param_1))\n","      elif activ_func == 'LogSigmoid':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.LogSigmoid())\n","      elif activ_func == 'PReLU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.PReLU())\n","      elif activ_func == 'ELU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.ELU(param_1))\n","      elif activ_func == 'ReLU6':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.ReLU6())\n","      elif activ_func == 'RReLU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.RReLU())\n","      elif activ_func == 'SELU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.SELU())\n","      elif activ_func == 'CELU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.CELU(param_1))\n","      elif activ_func == 'GELU':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.ReLU())  # for some reason GELU is not present; revert later if relevant\n","      elif activ_func == 'Sigmoid':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Sigmoid())\n","      elif activ_func == 'Softplus':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Softplus(param_1, param_2))\n","      elif activ_func == 'Softshrink':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Softplus(param_1))\n","      elif activ_func == 'Softsign':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Softsign())\n","      elif activ_func == 'Tanh':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Tanh())\n","      elif activ_func == 'Tanhshrink':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Tanhshrink())\n","      elif activ_func == 'Threshold':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Threshold(param_1, param_2))\n","      elif activ_func == 'Softmin':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Softmin())\n","      elif activ_func == 'Softmax':\n","        a_layer = nn.Sequential(\n","            weight_func(wf_param1, wf_param2),\n","            nn.Softmax())\n","      else:\n","        a_layer = weight_func(wf_param1, wf_param2)\n","\n","      return a_layer, num_nodes_out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"itPKtM0B1tNY","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DaRvVV5mDddf"},"source":["# Training and Test Functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R7H5AURDDe1w","colab":{}},"source":["# ==========================\n","# Train and test functions\n","# ==========================\n","\n","# Compute the number of parameters in a chromose (depends on limits)\n","def comp_num_chrom_param(limits):\n","  # Num. of training parameters\n","  tot_train_param = 4 # lr1, lr2, lr2 prop, momentum\n","  # Num. of pre-branch parameters\n","  tot_pre_branch = 1+(6*limits['max_pre_branch_layers']) # exist-or-not, layer params.\n","  # Num. of branch parameters\n","  tot_branch = (1+(6*limits['max_branch_layers']))*limits['max_branches']\n","  # Num. of post-branch parameters\n","  tot_post_branch = 1+(6*limits['max_post_branch_layers'])\n","\n","  return tot_train_param+tot_pre_branch+tot_branch+tot_post_branch\n","\n","# Interpret learning rate and momentum parameters\n","def interp_lrm(params):\n","  lr1 = scale_to_range(params[0], limits['lr1_min'], limits['lr1_,max'])\n","  lr2 = scale_to_range(params[1], limits['lr2_min'], limits['lr2_,max'])\n","  if lr1 < lr2:\n","    temp = lr1\n","    lr1 = lr2\n","    lr2 = temp\n","  lr2_epoch = (np.round(params[2]*args['num_epochs_search'])).astype(int)\n","  a_decr = (lr1-lr2)/lr2_epoch\n","  a_momentum = scale_to_range(params[3], limits['moment_min'], limits['moment_max'])\n","  return lr1, lr2, lr2_epoch, a_momentum, a_decr\n","\n","# Function to train a specific model\n","# Early stopping, or returning best validation model, is not implemented \n","def do_training(a_model, train_params, num_epochs):\n","\n","  lr1, lr2, lr2_epoch, a_momentum, lr_decr = train_params  \n","  args['lr'] = lr1\n","  args['momentum'] = a_momentum\n","\n","  optimizer = optim.SGD(a_model.parameters(), lr=args['lr'], momentum=args['momentum'])\n","  best_valid_accur = 0\n","  best_model = type(a_model)(a_model.chromosome) # get a new instance\n","  valid_accurs = []\n","  train_accurs = []\n","  train_start_time = time.time()\n","  for epoch in range(1, num_epochs + 1):\n","\n","    if args['verbose_train']:\n","      print('Epoch {} learning rate: {}.'.format(epoch, args['lr']))\n","\n","    train_one_epoch(a_model, optimizer, epoch, train_batches)\n","    \n","    a_train_accur = comp_accuracy(a_model, train_batches, num_train_instances)\n","    if args['verbose_train']:\n","      print('Training accuracy: {}%.'.format(a_train_accur))\n","    train_accurs.append(a_train_accur)\n","    \n","    a_valid_accur = comp_accuracy(a_model, valid_batches, num_valid_instances)\n","    if args['verbose_train']:\n","      print('Validation accuracy: {}%.'.format(a_valid_accur))\n","    valid_accurs.append(a_valid_accur)\n","    if a_valid_accur > best_valid_accur:\n","      best_valid_accur = a_valid_accur\n","      # best_model.load_state_dict(a_model.state_dict()) # copy weights and stuff\n","      best_model = copy.deepcopy(a_model)\n","\n","    # Decrement learning rate\n","    if epoch < lr2_epoch:\n","        args['lr'] -= lr_decr\n","        for param_group in optimizer.param_groups:\n","          param_group['lr'] = args['lr']\n","\n","  train_elapsed_time = time.time() - train_start_time\n","#   print('The training process took {} seconds.'.format(train_elapsed_time))\n","\n","  if args['cuda']:\n","      best_model.cuda()\n","\n","  return a_model, best_model, valid_accurs, train_accurs\n","  \n","# Create a random mask for DropCircuit\n","def make_mask(num_circuits, prob_drop):\n","  rand_vals = np.random.rand(num_circuits)\n","  decisions = rand_vals >= prob_drop\n","  a_mask = np.ones(num_circuits)*decisions\n","  # Must have at least one circuit active\n","  if np.sum(a_mask) == 0:\n","    rand_index = np.random.randint(num_circuits)\n","    a_mask[rand_index] = 1.0\n","\n","  return torch.from_numpy(a_mask)\n","\n","def train_one_epoch(a_model, optimizer, epoch, batches):\n","\n","  a_model.train()\n","  for batch_idx, (data, target) in enumerate(batches):\n","      if args['cuda']:\n","          data, target = data.cuda(), target.cuda()\n","      # Variables in Pytorch are differentiable. \n","      \n","      data, target = Variable(data), Variable(target)\n","      #This will zero out the gradients for this batch. \n","      optimizer.zero_grad()\n","      \n","      # Create DropCircuit mask\n","      dc_mask = make_mask(a_model.num_branches, args['dc_prob_drop'])\n","      \n","      output = a_model(data, dc_mask)\n","\n","      # Calculate the negative log likelihood loss.\n","      loss = F.nll_loss(output, target)\n","      #dloss/dx for every Variable \n","      loss.backward()\n","      # Gradient clipping\n","      torch.nn.utils.clip_grad_norm_(a_model.parameters(), args['clip_level'])\n","      #to do a one-step update on our parameter.\n","      optimizer.step()\n","      #Print out the loss periodically. \n","\n","  if args['verbose_train']:\n","    if epoch % args['log_interval_epoch'] == 0:\n","      print('Epoch: {}. Latest loss: {}.'.format(epoch, loss.data))\n","\n","# Compute accuracy\n","# The argument (data_source) of this function can be a data_loader or a list of batches (previously extracted) \n","def comp_accuracy(a_model, data_source, src_num_instances):\n","    a_model.eval()\n","    a_loss = 0\n","    correct = 0\n","    preds = torch.zeros(0)\n","    first = True\n","    for a_data_in, a_data_out in data_source:\n","        if args['cuda']:\n","            a_data_in, a_data_out = a_data_in.cuda(), a_data_out.cuda()\n","        a_data_in, a_data_out = Variable(a_data_in), Variable(a_data_out)\n","        output = a_model(a_data_in)\n","\n","        a_loss += F.nll_loss(output, a_data_out, reduction='sum').data # sum up batch loss\n","        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n","        if first:\n","          preds = pred\n","          first = False\n","        else:\n","          preds = torch.cat((preds, pred),0)\n","\n","        correct += pred.eq(a_data_out.data.view_as(pred)).long().cpu().sum()\n","\n","    # Compute and return accuracy\n","    if type(data_source) == list:  # case: list of batches\n","      result = 100. * (correct.numpy()/ src_num_instances)\n","    else: # case: data_loader\n","      result = 100. * (correct.numpy()/ len(data_source.dataset))\n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HRaTOxAyyXq2"},"source":["# Data Prep, Visualization (Histogram etc)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QPssuRVkyaWZ","colab":{}},"source":["# Check whether we have enough instances per class\n","# We want an imbalanced dataset but we don't want any specific label having\n","# an \"insufficient\" number of instances.\n","def check_enough_inst(batches, min_inst_per_class):\n","  \n","  # Concatenate training batch output labels\n","  labels = batches[0][1].numpy()\n","  for batch_i in range(1,args['num_train_batch']):\n","    new_labels = batches[batch_i][1].numpy()\n","    labels = np.concatenate((labels, new_labels))\n","\n","  labels = labels.tolist()\n","\n","  # Scan though labels\n","  for a_label in range(10):  # assuming MNIST, of course\n","    a_count = labels.count(a_label)\n","    # If label count is < min_inst_per_class return False\n","    if a_count < min_inst_per_class:\n","      return False\n","\n","  # Return True\n","  return True\n","\n","\n","# Prepare data. Extract training and validation batches\n","# This is where we make the problem \"small and imbalanced\"\n","def extract_batches(a_loader, min_inst_per_class, max_tries):\n","\n","  # Keep trying until you have a required minimum number of instances \n","  # per class in the training set (not elegant but ok for the range of \n","  # \"min_inst_per_class\" we need)\n","\n","  for ti in range(max_tries):\n","\n","    print('Data extraction trial {}.'.format(ti))\n","\n","    # Initializations\n","    train_batches = []\n","    valid_batches = []\n","    tot_batch_extract = args['num_train_batch'] + args['num_valid_batch']\n","\n","    # Extract\n","    for batch_idx, (data, target) in enumerate(a_loader):\n","\n","      if batch_idx < args['num_train_batch']:\n","        train_batches.append((data,target))\n","      else:\n","        valid_batches.append((data,target))\n","        if batch_idx == tot_batch_extract - 1:\n","          break\n","\n","    # Check minimum number of instances\n","    enough_instaces = check_enough_inst(train_batches, min_inst_per_class)\n","    if enough_instaces:\n","      return train_batches, valid_batches\n","\n","  print('It was not possible to create a dataset.')\n","  print('Consider increasing the overall number of instances, or')\n","  print('decreasing the minimum instances per class allowed.')\n","  return [], []\n","\n","# ===========================\n","# Display histogram of labels\n","# ===========================\n","\n","def disp_hist_labaels(batches):\n","  # Concatenate training batch output labels\n","  labels = batches[0][1].numpy()\n","  for batch_i in range(1,args['num_train_batch']):\n","    new_labels = batches[batch_i][1].numpy()\n","    labels = np.concatenate((labels, new_labels))\n","\n","  num_bins = 10\n","  n, bins, patches = plt.hist(labels, num_bins, facecolor='blue', alpha=0.5)\n","  plt.show()\n","\n","# This is not currently used\n","\n","# Display MNIST instances\n","# Adapted from # https://github.com/CSCfi/machine-learning-scripts/blob/master/notebooks/pytorch-mnist-mlp.ipynb\n","def disp_MNIST_inst(num_disp, X_train, y_train):\n","  pltsize=1\n","  plt.figure(figsize=(num_disp*pltsize, pltsize))\n","  for i in range(num_disp):\n","    plt.subplot(1,num_disp,i+1)\n","    plt.axis('off')\n","    plt.imshow(X_train[i,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n","    plt.title('Class: '+str(y_train[i].item()))\n","\n","\n","# Simple function to scale parameters\n","# num is assume to be \\in [0,1]\n","def scale_to_range(num,min_val,max_val):\n","  range = max_val - min_val\n","  return (num*range)+min_val\n","\n","# Generate a random chromosome where each param. is \\in [0,1)\n","def gen_rand_chromosome(num_param):\n","  chrom = np.random.rand(num_param)\n","  return chrom"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rFnBFgWOj_tc","outputId":"55cf0e70-77d7-4e14-e0b7-5e872e697b02","executionInfo":{"status":"ok","timestamp":1586243668653,"user_tz":-480,"elapsed":9580,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["test = np.random.rand(4)\n","\n","print(test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COLsvqUbw_sY"},"source":["# Display Data Distribution\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aAZmGY0M18aG","outputId":"0a0b15cf-2cc2-4973-b1b6-53559bb725b9","executionInfo":{"status":"ok","timestamp":1586243669412,"user_tz":-480,"elapsed":10311,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":321}},"source":["train_batches, valid_batches = extract_batches(train_loader, args['min_inst_class'], args['batch_max_tries'])\n","if args['verbose_train']:\n","  print('Extracted {} train_batches, and {} valid_batches.'.format(len(train_batches), len(valid_batches)))\n","\n","\n","disp_hist_labaels(train_batches)\n","\n","# ==========================\n","# Display dataset\n","# ==========================\n","\n","\n","if args['verbose_train']:\n","  X_train = train_batches[0][0]\n","  y_train = train_batches[0][1]\n","\n","  disp_MNIST_inst(10, X_train, y_train)\n","\n","  sum_train_0 = X_train[0,:,:].sum()\n","  min_train_0 = X_train[0,:,:].min()\n","  max_train_0 = X_train[0,:,:].max()\n","\n","  print('X_train[0,:,:] --> sum ({}); min ({}); max ({}).'.format(sum_train_0, min_train_0, max_train_0))\n","\n","# ==========================\n","# Design model\n","# ==========================\n","\n","# \"Unseed\" the rest\n","np.random.seed()\n","a_rand_seed = np.random.randint(0,999999)\n","torch.manual_seed(a_rand_seed)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data extraction trial 0.\n","Data extraction trial 1.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUuMMeklqnEEvSY37f09gaa2DGv3LAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f08e581f110>"]},"metadata":{"tags":[]},"execution_count":181}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mOXSLvfykNFo"},"source":["# **Work To be Done Starts Here**\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9T7bv9bDEiXo"},"source":["## Prepare Model, Neighbour Creation Functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QC-I7PqHEkeo","colab":{}},"source":["# Prepare model\n","def prepare_model(a_rand_chrom):\n","    # Initialize chromosome and model\n","    model = GBNDM(a_rand_chrom)\n","  \n","    if args['cuda']:\n","        model.cuda()\n","\n","    # Interpret learning rates and momentum\n","    lr1, lr2, lr2_epoch, a_momentum, lr_decr = interp_lrm(a_rand_chrom[0:4])\n","    train_params = (lr1, lr2, lr2_epoch, a_momentum, lr_decr)\n","    args['momentum'] = a_momentum\n","    if args['verbose_train']:\n","        print('lr1: {}'.format(lr1))\n","        print('lr2: {}'.format(lr2))\n","        print('lr2_epoch: {}'.format(lr2_epoch))\n","        print('a_momentum: {}'.format(a_momentum))\n","        print('lr_decr: {}'.format(lr_decr))\n","\n","    return model, train_params\n","\n","# Function for creating one neighbour\n","def create_a_neighbour(a_chromosome, neighbour_range, num_chrom_params):\n","    \n","    mutat_vec = (np.random.rand(num_chrom_params)*neighbour_range)-(neighbour_range/2)\n","\n","    # Add mutation vector\n","    new_chromosome = a_chromosome + mutat_vec\n","\n","    # Clip\n","    np.clip(new_chromosome, 0, 0.99999999999, out=new_chromosome)\n","\n","    return new_chromosome\n","\n","      \n","# Function for creating a list of neighbours\n","def create_neighbours(a_chromosome, meta, num_chrom_params):\n","    neighbours = []\n","    # Scan through number of neighbours\n","    for ni in range(meta['num_neighbours']):\n","        # Create neighbour\n","        a_neighb = create_a_neighbour(a_chromosome, meta['neighbour_range'], num_chrom_params)\n","        \n","        # Append neighbour\n","        neighbours.append(a_neighb)\n","\n","    return neighbours\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z7JIg_V2E3t5"},"source":["## Differential Search Function (To be looked at and worked on)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"afmMhfa-E5bG","colab":{}},"source":["# Simple differential search\n","def do_diff_chrom_v1(mat_chrom_accur, num_new_sol):\n","  \n","  # Initialize new chromosomes\n","    num_chrom = mat_chrom_accur.shape[0]\n","    if num_new_sol >= num_chrom:\n","        num_new_sol = num_chrom-1\n","    new_chromosomes = []\n","\n","    # Sort the array of chromosomes based on the first column (contains accur.)\n","    mat_chrom_accur = mat_chrom_accur[(-mat_chrom_accur[:,0]).argsort()]\n","    # print(mat_chrom_accur[:,0:4])\n","\n","    # Extract first/best chromosome\n","    best_chrom = mat_chrom_accur[0,1:]\n","\n","    # Scan through new solutions\n","    for si in range(num_new_sol):  \n","\n","        # Extract next best chrom\n","        next_best_chrom = mat_chrom_accur[1+si,1:]\n","\n","        # Compute differential\n","        a_diff = best_chrom - next_best_chrom\n","\n","        # Add differential whilst applying a learning rate\n","        a_new_chrom = best_chrom + (meta['diff_lr']*a_diff)\n","        np.clip(a_new_chrom, 0, 0.99999999999, out=a_new_chrom)\n","\n","        # Store new solution \n","        new_chromosomes.append(a_new_chrom)\n","\n","    return new_chromosomes\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PlUQsx5tFYB_"},"source":["## Model Test Function"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cs3abLvjFaRe","colab":{}},"source":["# ==========================\n","# Test final model / Visualize predictions\n","# ==========================\n","\n","def final_test(a_model):\n","    a_model.eval()\n","    test_loss = 0\n","    correct = 0\n","    test_preds = torch.zeros(0)\n","    first = True\n","    for test_data_in, test_data_out in test_loader: \n","\n","        if args['cuda']:\n","            test_data_in, test_data_out = test_data_in.cuda(), test_data_out.cuda()\n","                \n","        test_data_in, test_data_out = Variable(test_data_in), Variable(test_data_out)\n","        output = a_model(test_data_in)\n","        test_loss += F.nll_loss(output, test_data_out, reduction='sum').data # sum up batch loss\n","\n","        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n","        if first:\n","          test_preds = pred\n","          first = False\n","        else:\n","          test_preds = torch.cat((test_preds, pred),0)\n","\n","        correct += pred.eq(test_data_out.data.view_as(pred)).long().cpu().sum()\n","\n","    # Print test accuracy\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy (at final epoch): {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset), accuracy))\n","\n","    return accuracy\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TXbK2v51xMpH"},"source":["## Graph Plotting, Metric Calculation Functions\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZSjpMv1NyiC","colab":{}},"source":["def plot_bar(x_axis, y_axis):\n","    fig = plt.figure()\n","    ax = fig.add_axes([0,0,1,1])\n","    x_axis = ['Iteration {}'.format(i) for i in x_axis]\n","    ax.bar(x_axis, height = y_axis, width = 0.5)\n","    ax.set_ylabel('Accuracy')\n","    # ax.set_ylim(bottom = (0,100))\n","    ax.set_ybound(lower = 0, upper = 100)\n","    # ax.set_yticks(y_axis) # displays the exact ticks\n","    plt.show()\n","\n","def plot_bar_2(x_axis, y_axis):\n","\n","    # Specifies the positions on the x_axis for ticks to be labeled\n","    y_pos = np.arange(len(x_axis))\n","\n","    # Formatting for the x_axis labels\n","    objects = ['Trial {}'.format(i+1) for i in x_axis]\n","\n","    # Calculate metrics for error bar handling\n","    std_dev, mean, variance = calculate_metrics(y_axis)\n","\n","    # Plot bar graph\n","    plt.bar(y_pos, y_axis, align='center', alpha=0.5, color ='b', yerr=std_dev, tick_label = y_axis)\n","    plt.xticks(y_pos, objects, rotation = 90)\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracies over 10 trials')\n","    file_name = 'Mean Accuracy {}.png'.format(mean)\n","    plt.savefig(file_name, bbox_inches='tight')\n","\n","    files.download(file_name)\n","\n","    \n","def plot_line_graph(x_axis, y_axis):\n","    # Specifies the positions on the x_axis for ticks to be labeled\n","    y_pos = np.arange(len(x_axis))\n","\n","    # Formatting for the x_axis labels\n","    objects = ['Iteration {}'.format(i+1) for i in x_axis]\n","\n","    obj = dict(zip(y_pos, y_axis))\n","\n","    # plt.plot('Iterations', 'Accuracy', data=obj)\n","    plt.plot(y_pos, y_axis)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracies of every model')\n","\n","def calculate_metrics(y_axis):\n","\n","    # Error bar handling\n","    std_dev = np.std(y_axis)\n","    mean = np.mean(y_axis)\n","    variance = np.var(y_axis)\n","\n","    print('Mean accuracy of models are {}'.format(mean))\n","    print('Mean variance of results is {}'.format(variance))\n","    print('Standard deviation of results is {}'.format(std_dev))\n","\n","    return std_dev, mean, variance"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JqEVks-MFrRP"},"source":["## File read/write\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PogkXQBCI0yo","colab":{}},"source":["def load_from_csv(path):\n","    '''\n","    Loads the chromosome from path specified into a np array\n","\n","    Args:\n","    path: Path where chromosome is located\n","    e.g path='gdrive/My Drive/Chromosome Saves/chrom_acc72'\n","\n","    Returns:\n","    None\n","    '''\n","    drive.mount('/content/gdrive/')\n","    some_file = np.genfromtxt(path, dtype='float', delimiter=',')\n","\n","    return some_file\n","\n","def update_file_with_metrics(path,iterations, evaluations, time_taken, y_axis, parameter_dict, learning_rate_list):\n","    drive.mount('/content/gdrive/')\n","\n","    std_dev, mean, variance = calculate_metrics(y_axis)\n","    temp_counter = 0\n","    datetime_now = datetime.now() + timedelta(hours=8)\n","\n","    with open(path+'results.txt', 'a+') as f:\n","        f.write('================================\\n')\n","        f.write('New Results\\n')\n","        f.write('================================\\n')\n","        f.write(datetime_now.strftime('%Y-%b-%d, %H%M hours\\n'))\n","        f.write(f'Trials used: {iterations}\\n')\n","        f.write(f'Mean accuracy: {mean}\\n')\n","        f.write(f'Number of evaluations taken: {evaluations}\\n')\n","        f.write(f'Time taken: {time_taken}\\n')\n","        f.write(f'Standard deviation: {std_dev}\\n')\n","        f.write(f'Variance: {variance}\\n')\n","\n","        for key,value in parameter_dict.items():\n","            f.write(f'{key}: {value}\\n')\n","\n","        f.write('List of Accuracies: \\n')\n","        f.write(f'{str(y_axis)}\\n')\n","\n","        f.write(f'List of diff search learning rates: {learning_rate_list}\\n')\n","        for values in learning_rate_list:\n","            temp_counter += values\n","        temp_counter /= iterations\n","        f.write(f'Average learning rate for differential search: {temp_counter}\\n')\n","        f.write('\\n')       \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TRsXu3X1toBF"},"source":["## Chromosome Evaluation function"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CxJe7O5wtrQn","colab":{}},"source":["# Evaluate a list of chromosomes\n","def eval_chromosomes(list_chromosomes,num_chrom_params):\n","    '''\n","    Evaluates a list of x chromosomes and chooses the best one, where x is number of neighbours specified\n","    \n","    Args:\n","    list_chromosomes: list, containing list of values\n","    num_chrom_params: int, number of parameters a chromosome has\n","\n","    Returns:\n","    best_res: tuple, containg the best results, could be from different chromosomes\n","    temp_list: list, containing dicts of chromosomes\n","    '''\n","\n","    # best_model_accur, best_chromosome, best_model, best_train_params = best_res\n","\n","    best_model_accur = 0\n","    best_chromosome = None\n","    best_model = None\n","    best_train_params = None\n","\n","    num_chrom = len(list_chromosomes)\n","\n","    temp_tuple = ()\n","    temp_list = []\n","\n","    # List of zeroes in the shape [num_chrom, 1+num_chrom_params]\n","    mat_chrom_acur = np.zeros((num_chrom, 1+num_chrom_params))\n","    neighb_valid_accurs = []\n","\n","    for ci, a_chrom in enumerate(list_chromosomes):\n","        # if args['verbose_meta']:\n","        #     print('Chromosome {} ...'.format(ci))\n","\n","        # --- Actual training\n","        model, train_params = prepare_model(a_chrom)\n","        model, valid_accurs, train_accurs = do_eval_chrom(model, train_params, args['num_epochs_search'])\n","        best_valid_accur = max(valid_accurs)\n","\n","        # Store chromosome and accuracy\n","        # mat_chrom_acur will be a (2,376) np array\n","        mat_chrom_acur[ci,0] = best_valid_accur\n","        mat_chrom_acur[ci,1:] = a_chrom\n","        print('Best validation accuracy: {}%.'.format(best_valid_accur))\n","        neighb_valid_accurs.append(best_valid_accur)\n","\n","        if best_valid_accur > best_model_accur:\n","            best_model_accur = best_valid_accur\n","            best_chromosome = a_chrom\n","            best_model = model\n","            best_train_params = train_params\n","\n","        temp_tuple = (best_valid_accur, a_chrom, model, train_params)\n","\n","        temp_list.append(temp_tuple)\n","\n","        # if args['verbose_meta']:\n","        #     print('*** Improving validation accuracy: {}.'.format(best_model_accur))\n","\n","    best_res = (best_model_accur, best_chromosome, best_model, best_train_params)\n","    return best_res, mat_chrom_acur,temp_list\n","\n","# Add early stopping if algorithm does not progress well here\n","def do_eval_chrom(a_model, train_params, num_epochs):\n","    '''\n","    Chromosome evaluation (more efficient than do_training)\n","    Function to train a specific model\n","    Early stopping, or returning best validation model, is not implemented \n","    '''\n","\n","    # Extract basic information\n","    lr1, lr2, lr2_epoch, a_momentum, lr_decr = train_params  \n","    args['lr'] = lr1\n","    args['momentum'] = a_momentum\n","\n","    optimizer = optim.SGD(a_model.parameters(), lr=args['lr'], momentum=args['momentum'])\n","    valid_accurs = []\n","    train_accurs = []\n","    train_start_time = time.time()\n","    for epoch in range(1, num_epochs + 1):\n","\n","        if args['verbose_train']:\n","            print('Epoch {} learning rate: {}.'.format(epoch, args['lr']))\n","\n","        train_one_epoch(a_model, optimizer, epoch, train_batches)\n","        a_train_accur = comp_accuracy(a_model, train_batches, num_train_instances)\n","\n","        if args['verbose_train']:\n","            print('Training accuracy: {}%.'.format(a_train_accur))\n","        train_accurs.append(a_train_accur)\n","        a_valid_accur = comp_accuracy(a_model, valid_batches, num_valid_instances)\n","\n","        if args['verbose_train']:\n","            print('Validation accuracy: {}%.'.format(a_valid_accur))\n","        valid_accurs.append(a_valid_accur)\n","\n","        # Decrement learning rate\n","        if epoch < lr2_epoch:\n","            args['lr'] -= lr_decr\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = args['lr']\n","\n","    train_elapsed_time = time.time() - train_start_time\n","    # print('The training process took {} seconds.'.format(train_elapsed_time))\n","\n","    return a_model, valid_accurs, train_accurs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vRtllDvYG9wi"},"source":["## Architectural Search (Work on this part)"]},{"cell_type":"code","metadata":{"colab_type":"code","cellView":"code","id":"IUPxCjD-C9lO","outputId":"5a637c4d-479d-426c-8363-ddf2da46d86c","executionInfo":{"status":"ok","timestamp":1586245024381,"user_tz":-480,"elapsed":1365186,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#@title\n","# ================================\n","# Architectureal search\n","# ================================\n","\n","# Artificial Intelligence Methods students should focus on the code below.\n","# You should keep the neural network code unchaged. This is crucial for \n","# comparison purposes. In other words, focus only on modifying the architecture\n","# search code below.\n","\n","# --- Architectural search parameters\n","meta = {}\n","meta['max_rs_iter'] = 10 # 10  # initial random search\n","meta['max_shc_iter'] = 20 # 40 # 20 # 40  # stochastic hill climbing iterations\n","meta['num_neighbours'] = 10 # 16 \n","meta['neighbour_range'] = 0.7  # 0.2  # mutation rate for stochastic hill-climbing\n","meta['num_differential_sol'] = 6 # 8 # number of differential evolution solutions\n","meta['diff_lr'] = 0.1 # 0.1 # learning rate for differential search\n","\n","evaluation_counter = 0 \n","diff_lr_list = []\n","\n","# Performing the search based off the number of iterations defined in settings\n","x_axis_plot = []\n","y_axis_plot = []\n","\n","# Starting time of 10 iterations\n","total_time_taken = 0\n","iteration_start_time = time.time()\n","\n","for trials in tqdm(range(10)): # 10 iterations\n","    print('======================================')\n","    print('THIS IS ITERATION {}'.format(trials))\n","    print('======================================')\n","\n","    # Each trial must be independent, hence initialize variables to their originals\n","    meta_rs_valids = [] # List that will contain best validation accuracies\n","    best_model = None\n","    best_chromosome = None\n","    best_model_accur = 0\n","    meta['diff_lr'] = 0.1 # Reinitialize learning rate every iteration\n","\n","    # Used to store the chromosomes that are generated from random search\n","    random_search_times = 0\n","    random_search_condition = True\n","    temp_rs_list = []\n","    temp_rs_dict = {}\n","\n","    # Stochastic hill climbing variables\n","    shc_reinitialize_counter = 0\n","    temp_shci_values_list = []\n","\n","    prev_accur = 0\n","    move_counter = 0\n","    diff_counter = 0\n","\n","    # Differential search variables\n","    temp_diff_list = []\n","    temp_diff_res = ()\n","\n","    # While true and still less than 10 times\n","    while random_search_condition and random_search_times < 10:\n","        random_search_times += 1\n","        print('Back at the top of the while loop!, number of search times is {}\\n'.format(random_search_times))\n","\n","        # Start with a small random search\n","        print('Initital random search ...')\n","        for rsi in tqdm(range(meta['max_rs_iter'])):\n","            if args['verbose_meta']:\n","                print('Search iteration {}.\\n'.format(rsi+1))\n","\n","            num_chrom_param = comp_num_chrom_param(limits)\n","\n","            # Generate random chromosomes\n","            a_rand_chrom = gen_rand_chromosome(num_chrom_param)\n","\n","            # --- Actual training\n","            model, train_params = prepare_model(a_rand_chrom)\n","\n","            # New model after evaluation\n","            model, valid_accurs, train_accurs = do_eval_chrom(model, train_params, args['num_epochs_search'])\n","            evaluation_counter += 1\n","            best_valid_accur = max(valid_accurs)\n","            print('Best validation accuracy: {}%.\\n'.format(best_valid_accur))\n","\n","            # Store best model\n","            if best_valid_accur > best_model_accur:\n","                best_model_accur = best_valid_accur\n","                best_model = model\n","                best_train_params = train_params\n","                best_chromosome = a_rand_chrom\n","\n","            # Best validation accuracy is put into a list\n","            meta_rs_valids.append(best_valid_accur)\n","            x = np.amax(meta_rs_valids) \n","\n","            temp_tuple = (best_valid_accur, model, train_params, a_rand_chrom)\n","            temp_rs_list.append(temp_tuple)\n","\n","        if x <= 15:\n","            print(f'Not yet\\n')\n","            continue\n","\n","        else:\n","            print(f'Found the value we wanted which is {x}\\n')\n","            random_search_condition = False\n","        # end inner for\n","    # end outer while\n","\n","    if random_search_condition == True:\n","        # Sort by accuracy (first element in tuple)\n","        temp_rs_list.sort(key = lambda x: x[0], reverse=True) \n","\n","        best_model_accur = temp_rs_list[0][0]\n","        best_model = temp_rs_list[0][1]\n","        best_train_params = temp_rs_list[0][2]\n","        best_chromosome = temp_rs_list[0][3]\n","\n","    print('*****************************************************')\n","    print('Best accuracy after initial random search: {}'.format(best_model_accur))\n","    print('*****************************************************')\n","\n","    if args['verbose_meta']:\n","        print('Best validation errors: {}\\n'.format(meta_rs_valids))\n","        \n","    # # --- Stochastic hill climbing\n","    num_chrom_params = best_chromosome.shape[0] # Number of parameters in the chromosome (1st argument of tuple) - 376 params\n","\n","    # Architectural search iterations\n","    best_res = (best_model_accur, best_chromosome, best_model, best_train_params) \n","    meta_start_time = time.time()\n","\n","    # Does stochastic hill climbing for ['max_shc_iter'] times\n","    for shci in range(meta['max_shc_iter']):\n","\n","        # Maybe omitting this part in favor of the later part is better.\n","        # Perhaps keep the differential search counter one , comment out this one \n","        if shc_reinitialize_counter == 3:\n","            meta['diff_lr'] = 0.1 # Reinitialize learning rate every iteration\n","            temp_rs_list.sort(key = lambda x: x[0], reverse=True) \n","            temp_diff_list.sort(key = lambda tuples: tuples[0], reverse=True)\n","\n","            if temp_diff_list[move_counter][0] > temp_rs_list[move_counter][0]:\n","                best_model_accur = temp_diff_list[move_counter][0]\n","                best_chromosome = temp_diff_list[move_counter][1]\n","                best_model = temp_diff_list[move_counter][2]\n","                best_train_params = temp_diff_list[move_counter][3]\n","                print('Picked from diff list\\n')\n","                # Error here\n","            else:\n","                best_model_accur = temp_rs_list[move_counter][0]\n","                best_model = temp_rs_list[move_counter][1]\n","                best_train_params = temp_rs_list[move_counter][2]\n","                best_chromosome = temp_rs_list[move_counter][3]\n","                print('Picked from random search list\\n')\n","\n","            shc_reinitialize_counter = 0 \n","            move_counter += 1\n","\n","            print('******************************************************************************')\n","            print(f'The reinitialization counter is {shc_reinitialize_counter}, changing chromosome\\n')\n","            print(f'Accuracy of this chromosome is {best_model_accur}\\n')\n","            print(f'The current move counter is {move_counter}\\n')\n","            print('******************************************************************************')\n","\n","            diff_counter = 0\n","            best_res = (best_model_accur, best_chromosome, best_model, best_train_params)\n","\n","        best_model_accur, best_chromosome, best_model, best_train_params = best_res\n","            \n","        if args['verbose_meta']:\n","            print('======================================')\n","            print('Stochastic hill-climbing iteration {}.'.format(shci))\n","            print('======================================')\n","            print('Best accuracy so far: {}'.format(best_model_accur))\n","            print('======================================')\n","\n","        # --- Create a set of stochastic neighbours from the current best model\n","        chrom_neighbors = create_neighbours(best_chromosome, meta, num_chrom_params)\n","\n","        # Test validation accuracies of neighbours\n","        # Takes in a list of neighbours and evaluates them\n","        new_res, mat_chrom_acur, other_neighbours = eval_chromosomes(chrom_neighbors,num_chrom_params)\n","\n","        # Validating how good the neighbours are compared to the current best solution\n","        if new_res[0] >= best_res[0]:\n","            best_res = new_res \n","\n","        print('***********************************************')\n","        print('Best accuracy after random mutation: {}'.format(new_res[0]))\n","        print('***********************************************')\n","        print('\\n')\n","            \n","    # end stochastic hill climbing\n","\n","        # --- Simple differential search\n","        print('***** Differential Search *********************')\n","        # if diff_counter >= 3:\n","            # print('Results stagnating so picking best res from new res\\n')\n","            # # Picks the best chromosome from the differential search\n","            \n","            # temp_diff_list.sort(key = lambda x: x[0], reverse=True) \n","            # best_res = temp_diff_list[move_counter]\n","\n","            # move_counter += 1\n","            # diff_counter = 0\n","            # meta['diff_lr'] = 0.1\n","\n","            # diff_chromosomes = do_diff_chrom_v1(mat_chrom_acur, meta['num_differential_sol'])\n","            # new_res, mat_chrom_acur, other_neighbours2 = eval_chromosomes(diff_chromosomes,num_chrom_params)\n","\n","        # else:\n","        # Picks the best chromosome from the differential search\n","        diff_chromosomes = do_diff_chrom_v1(mat_chrom_acur, meta['num_differential_sol'])\n","        new_res, mat_chrom_acur, other_neighbours2 = eval_chromosomes(diff_chromosomes,num_chrom_params)\n","\n","        # If the new best accuracy is better than the current accuracy\n","        if new_res[0] > best_res[0]:\n","            best_res = new_res\n","            diff_counter = 0\n","        \n","        else:\n","            temp_diff_list.append(new_res)\n","\n","        # # Checking whether the accuracy has stagnated across past 2 iterations\n","        # else:\n","        #     counter = 0\n","        #     temp_list = []\n","        #     temp_list.append(best_res[0])\n","        #     for i in range(len(temp_list)):\n","        #         # If the accuracy is the same as the first item in the array\n","        #         if best_res[0] == i:\n","        #             counter = counter + 1\n","        #             continue\n","\n","        #         # Can include check for learning rate here\n","        #         elif best_res[0] < i:\n","        #             # if the results decrease or stay the same, decrease learning rate\n","        #             meta['diff_lr'] = meta['diff_lr'] - 0.05\n","\n","        #     # If results are stagnating\n","        #     if counter == 2:\n","        #         if meta['diff_lr'] <= 0.6:\n","        #             meta['diff_lr'] = meta['diff_lr'] + 0.05\n","\n","        print('Current learning rate: {}\\n'.format(meta['diff_lr']))\n","\n","        print('***********************************************')\n","        print('Best accuracy after differential search: {}'.format(new_res[0]))\n","        print('***********************************************')\n","\n","        meta_elapsed_time = time.time() - meta_start_time\n","\n","        if args['verbose_meta']:\n","            print('=====================================================')\n","            print('Architectural optimization total time: {}.'.format(meta_elapsed_time))\n","            print('=====================================================')\n","        \n","        # Final visualization\n","        print('======================================')\n","        print('Best accuracy so far: {}'.format(best_res[0]))\n","        print('======================================')\n","\n","        print('Computing the final test ...')\n","        best_model_accur, best_chromosome, best_model, best_train_params = best_res\n","        final_model, best_valid_model, valid_accurs, train_accurs = do_training(best_model, best_train_params, args['num_epochs_test'])\n","\n","        print('=====================================')\n","        print('Training accuracies')\n","        print('=====================================')\n","        print(train_accurs)\n","\n","        print('=====================================')\n","        print('Best training parameters')\n","        print('=====================================')\n","        print(best_train_params)\n","\n","        # print('=====================================')\n","        # print('Best model')\n","        # print('=====================================')\n","        # print(best_valid_model)\n","\n","        print('=====================================')\n","        print('Test accuracies')\n","        print('=====================================')\n","\n","        print('Model with best validation accuracy: ')\n","        accur_valid = final_test(best_valid_model)\n","\n","        print('Model at the end of training: ')\n","        accur_final = final_test(final_model)\n","\n","        max_accur = int(max(accur_valid, accur_final))\n","        \n","        # Break shci if more than 70 else continue\n","        if max_accur > 69:\n","            print(f'Early stop, accuracy is {max_accur}')\n","            shc_reinitialize_counter = 0\n","            break\n","                    \n","        # else:\n","        #     if max_accur >= 60 and max_accur < 70:\n","        #         meta['diff_lr'] += 0.02\n","        #         if max_accur <= prev_accur:\n","        #             diff_counter += 1\n","        #     else: \n","        #         diff_counter += 1\n","        else:\n","            if max_accur <= prev_accur:\n","                if max_accur >= 60 and max_accur < 70:\n","                    meta['diff_lr'] += 0.001\n","                    shc_reinitialize_counter += 1\n","                else:\n","                    meta['diff_lr'] += 0.005\n","                    shc_reinitialize_counter += 1\n","                    diff_counter += 1\n","\n","            # elif max_accur == prev_accur:\n","            #     shc_reinitialize_counter += 1\n","            #     diff_counter += 1\n","\n","            else: \n","                shc_reinitialize_counter = 0\n","                diff_counter = 0 \n","\n","        print(f'Diff counter is {diff_counter}\\n')\n","        print(f'The shc reinitialization counter is {shc_reinitialize_counter}\\n')\n","        print(f'Prev accuracy is {prev_accur} and max_accur is {max_accur}\\n')\n","        prev_accur = max_accur\n","\n","    # end shc for loop\n","    # Creating a list of values to plot graph / statistical analysis\n","    x_axis_plot.append(iterations)\n","    y_axis_plot.append(max_accur)\n","    diff_lr_list.append(meta['diff_lr'])\n","    \n","    total_time_taken = time.time() - iteration_start_time\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"},{"output_type":"stream","text":["======================================\n","THIS IS ITERATION 0\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n","Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.56it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 4\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 2.\n","\n","Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 27.700000000000003%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Found the value we wanted which is 27.700000000000003\n","\n","*****************************************************\n","Best accuracy after initial random search: 27.700000000000003\n","*****************************************************\n","Best validation errors: [9.8, 9.8, 9.8, 9.8, 9.8, 10.7, 9.8, 10.7, 10.9, 9.8, 10.9, 9.8, 10.9, 10.9, 10.7, 9.8, 10.7, 9.8, 9.8, 9.8, 9.8, 9.8, 10.9, 10.7, 9.8, 10.9, 10.9, 9.8, 9.8, 10.7, 10.5, 9.8, 27.700000000000003, 9.8, 9.8, 10.7, 10.5, 9.8, 9.8, 10.9]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 27.700000000000003\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 11.200000000000001%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 20.200000000000003%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","***********************************************\n","Best accuracy after random mutation: 20.200000000000003\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 28.7%.\n","Best validation accuracy: 20.4%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 28.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 3.3587074279785156.\n","=====================================================\n","======================================\n","Best accuracy so far: 28.7\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[49.0, 45.0, 49.0, 55.00000000000001, 46.0, 40.0, 62.0, 66.0, 55.00000000000001, 71.0, 67.0, 59.0, 65.0, 56.00000000000001, 68.0, 63.0, 78.0, 71.0, 69.0, 69.0, 62.0, 81.0, 76.0, 74.0, 86.0, 59.0, 56.00000000000001, 55.00000000000001, 69.0, 63.0, 78.0, 82.0, 83.0, 83.0, 85.0, 88.0, 71.0, 85.0, 70.0, 88.0, 91.0, 77.0, 75.0, 93.0, 83.0, 83.0, 78.0, 81.0, 89.0, 92.0, 91.0, 96.0, 94.0, 91.0, 83.0, 86.0, 75.0, 95.0, 89.0, 90.0, 88.0, 91.0, 90.0, 92.0, 88.0, 70.0, 91.0, 80.0, 76.0, 98.0, 86.0, 94.0, 97.0, 98.0, 96.0, 91.0, 80.0, 93.0, 92.0, 96.0, 99.0, 98.0, 100.0, 90.0, 99.0, 87.0, 93.0, 98.0, 100.0, 98.0, 89.0, 100.0, 100.0, 97.0, 96.0, 93.0, 93.0, 100.0, 96.0, 95.0, 100.0, 99.0, 100.0, 100.0, 99.0, 98.0, 99.0, 100.0, 99.0, 100.0, 100.0, 99.0, 91.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 98.0, 96.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 98.0, 98.0, 94.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 95.0, 98.0, 97.0, 100.0, 100.0, 99.0, 98.0, 93.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 96.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 94.0, 99.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 95.0, 100.0, 98.0, 100.0, 99.0, 100.0, 98.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 98.0, 97.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 99.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 99.0, 97.0, 94.0, 95.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.6451876088571942, 0.8440352882707182, 7, 0.41943983461289175, 0.11445033151235372)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 6.8644, Accuracy (at final epoch): 6858/10000 (69%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 7.6260, Accuracy (at final epoch): 6777/10000 (68%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 0 and max_accur is 68\n","\n","======================================\n","Stochastic hill-climbing iteration 1.\n","======================================\n","Best accuracy so far: 28.7\n","======================================\n","Best validation accuracy: 26.5%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 33.300000000000004%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 20.4%.\n","Best validation accuracy: 36.4%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 36.4\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 44.3%.\n","Best validation accuracy: 44.5%.\n","Best validation accuracy: 33.900000000000006%.\n","Best validation accuracy: 30.4%.\n","Best validation accuracy: 28.7%.\n","Best validation accuracy: 63.9%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 63.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 32.58214330673218.\n","=====================================================\n","======================================\n","Best accuracy so far: 63.9\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[94.0, 93.0, 84.0, 86.0, 81.0, 95.0, 93.0, 91.0, 97.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.4483842692786628, 6, 0.5445387271754266, 0.25860262178355786)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 1.5232, Accuracy (at final epoch): 7316/10000 (73%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [01:10<10:34, 70.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 2.1791, Accuracy (at final epoch): 7313/10000 (73%)\n","\n","Early stop, accuracy is 73\n","======================================\n","THIS IS ITERATION 1\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:01,  2.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n","Best validation accuracy: 9.8%.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 16.1%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.54it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Found the value we wanted which is 16.1\n","\n","*****************************************************\n","Best accuracy after initial random search: 16.1\n","*****************************************************\n","Best validation errors: [10.9, 10.7, 9.8, 9.8, 9.8, 10.7, 10.7, 10.7, 9.8, 9.8, 10.7, 10.9, 10.7, 9.8, 10.7, 9.8, 9.8, 10.7, 10.9, 10.7, 10.7, 9.8, 16.1, 10.7, 10.9, 10.9, 10.5, 10.7, 9.8, 10.7]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 16.1\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 10.7\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 3.797234296798706.\n","=====================================================\n","======================================\n","Best accuracy so far: 16.1\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 39.0, 20.0, 20.0, 20.0, 33.0, 42.0, 43.0, 39.0, 40.0, 44.0, 44.0, 70.0, 41.0, 46.0, 74.0, 66.0, 68.0, 51.0, 70.0, 70.0, 72.0, 56.00000000000001, 69.0, 77.0, 80.0, 98.0, 83.0, 73.0, 73.0, 89.0, 87.0, 93.0, 83.0, 86.0, 84.0, 93.0, 96.0, 97.0, 94.0, 78.0, 90.0, 100.0, 100.0, 98.0, 100.0, 96.0, 100.0, 97.0, 74.0, 95.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(0.7137367880676433, 0.4608769895993773, 8, 0.3156445861021759, 0.03160747480853325)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 1.6615, Accuracy (at final epoch): 7203/10000 (72%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [01:50<08:09, 61.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 2.0705, Accuracy (at final epoch): 7050/10000 (70%)\n","\n","Early stop, accuracy is 72\n","======================================\n","THIS IS ITERATION 2\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:01<00:00,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.46it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:01<00:02,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  2.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:02<00:01,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:01,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 14.899999999999999%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.00it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:01<00:02,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  2.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:02<00:01,  3.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:01,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 20.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:03<00:00,  2.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  2.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Found the value we wanted which is 20.9\n","\n","*****************************************************\n","Best accuracy after initial random search: 20.9\n","*****************************************************\n","Best validation errors: [9.8, 10.9, 9.8, 10.9, 9.8, 10.7, 10.7, 9.8, 10.9, 9.8, 10.9, 9.8, 9.8, 10.7, 10.7, 10.9, 10.9, 10.7, 14.899999999999999, 10.9, 10.7, 10.7, 9.8, 10.9, 9.8, 9.8, 20.9, 9.8, 9.8, 10.7]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 20.9\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 4.6332597732543945.\n","=====================================================\n","======================================\n","Best accuracy so far: 20.9\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[10.0, 22.0, 20.0, 33.0, 15.0, 17.0, 45.0, 22.0, 54.0, 38.0, 40.0, 28.999999999999996, 28.000000000000004, 32.0, 50.0, 51.0, 49.0, 47.0, 54.0, 54.0, 54.0, 48.0, 47.0, 47.0, 56.99999999999999, 62.0, 69.0, 57.99999999999999, 76.0, 65.0, 76.0, 74.0, 80.0, 79.0, 67.0, 80.0, 74.0, 67.0, 75.0, 70.0, 76.0, 71.0, 75.0, 86.0, 82.0, 85.0, 80.0, 99.0, 87.0, 88.0, 86.0, 74.0, 87.0, 85.0, 90.0, 79.0, 97.0, 86.0, 93.0, 91.0, 90.0, 71.0, 84.0, 80.0, 85.0, 94.0, 89.0, 100.0, 95.0, 76.0, 96.0, 95.0, 94.0, 85.0, 96.0, 90.0, 94.0, 94.0, 89.0, 98.0, 89.0, 100.0, 100.0, 89.0, 100.0, 100.0, 92.0, 84.0, 97.0, 96.0, 98.0, 100.0, 96.0, 91.0, 100.0, 96.0, 99.0, 94.0, 94.0, 100.0, 89.0, 99.0, 96.0, 96.0, 93.0, 100.0, 96.0, 100.0, 89.0, 100.0, 100.0, 96.0, 100.0, 98.0, 100.0, 100.0, 90.0, 100.0, 98.0, 99.0, 100.0, 100.0, 95.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 97.0, 98.0, 96.0, 89.0, 96.0, 97.0, 95.0, 94.0, 95.0, 94.0, 99.0, 99.0, 100.0, 95.0, 96.0, 100.0, 100.0, 100.0, 97.0, 91.0, 100.0, 99.0, 100.0, 100.0, 100.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 99.0, 96.0, 94.0, 94.0, 94.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 96.0, 99.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 92.0, 90.0, 100.0, 100.0, 100.0, 100.0, 98.0, 91.0, 94.0, 100.0, 90.0, 88.0, 99.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 98.0, 98.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 91.0, 100.0, 100.0, 100.0, 93.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 91.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 93.0, 90.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 89.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 100.0, 91.0, 91.0, 98.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.990872576843439, 1.1089493766179832, 2, 0.16841298406923652, 0.4409616001127279)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 3.4157, Accuracy (at final epoch): 7398/10000 (74%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [02:42<06:50, 58.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 4.4784, Accuracy (at final epoch): 7359/10000 (74%)\n","\n","Early stop, accuracy is 73\n","======================================\n","THIS IS ITERATION 3\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:01,  4.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  4.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.0%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.39it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.24it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.0%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 4\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 5\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:01,  4.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.0%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:00<00:01,  4.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:01<00:00,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.37it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 6\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 12.4%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:01<00:00,  3.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.33it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 7\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 16.1%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Found the value we wanted which is 16.1\n","\n","*****************************************************\n","Best accuracy after initial random search: 16.1\n","*****************************************************\n","Best validation errors: [10.9, 9.8, 10.7, 9.8, 10.9, 9.8, 10.7, 10.0, 10.9, 9.8, 9.8, 10.7, 10.9, 9.8, 10.7, 9.8, 9.8, 10.7, 10.7, 9.8, 10.7, 9.8, 10.0, 10.7, 10.7, 10.7, 9.8, 9.8, 10.7, 10.7, 9.8, 10.7, 10.9, 10.7, 10.9, 9.8, 9.8, 10.9, 9.8, 10.7, 9.8, 10.7, 10.0, 10.7, 10.7, 9.8, 9.8, 9.8, 10.7, 9.8, 9.8, 10.9, 12.4, 10.9, 10.7, 10.9, 9.8, 10.7, 10.9, 10.9, 10.9, 10.7, 10.7, 9.8, 10.7, 16.1, 10.7, 9.8, 9.8, 10.7]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 16.1\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 29.5%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 29.5\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 20.4%.\n","Best validation accuracy: 20.1%.\n","Best validation accuracy: 42.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 11.600000000000001%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 42.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 4.57874608039856.\n","=====================================================\n","======================================\n","Best accuracy so far: 42.9\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[62.0, 68.0, 56.99999999999999, 63.0, 56.00000000000001, 61.0, 56.00000000000001, 62.0, 54.0, 75.0, 54.0, 72.0, 69.0, 57.99999999999999, 83.0, 82.0, 94.0, 83.0, 72.0, 73.0, 74.0, 80.0, 93.0, 90.0, 97.0, 98.0, 91.0, 93.0, 99.0, 100.0, 98.0, 86.0, 99.0, 94.0, 91.0, 96.0, 95.0, 90.0, 96.0, 96.0, 86.0, 85.0, 88.0, 88.0, 96.0, 96.0, 98.0, 98.0, 97.0, 95.0, 99.0, 96.0, 100.0, 96.0, 85.0, 80.0, 84.0, 91.0, 97.0, 99.0, 100.0, 96.0, 100.0, 99.0, 96.0, 96.0, 97.0, 97.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 99.0, 99.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.9006978451139334, 0.3069469323385523, 0, 0.6488201326190438, inf)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 1.5201, Accuracy (at final epoch): 7245/10000 (72%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [03:35<05:41, 56.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 5.2343, Accuracy (at final epoch): 7228/10000 (72%)\n","\n","Early stop, accuracy is 72\n","======================================\n","THIS IS ITERATION 4\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  2.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  2.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:01,  4.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:01,  4.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:01<00:02,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 4\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 20.200000000000003%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Found the value we wanted which is 20.200000000000003\n","\n","*****************************************************\n","Best accuracy after initial random search: 20.200000000000003\n","*****************************************************\n","Best validation errors: [9.8, 9.8, 10.9, 10.7, 9.8, 10.7, 10.7, 10.9, 9.8, 10.9, 10.9, 10.7, 10.7, 10.9, 10.7, 10.7, 9.8, 10.7, 9.8, 10.9, 10.7, 9.8, 10.7, 9.8, 9.8, 10.5, 10.7, 9.8, 10.7, 9.8, 9.8, 10.7, 10.9, 9.8, 10.7, 10.9, 20.200000000000003, 10.5, 10.9, 9.8]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 20.200000000000003\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","Best validation accuracy: 13.100000000000001%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 13.100000000000001\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 12.7%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 12.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 6.407109498977661.\n","=====================================================\n","======================================\n","Best accuracy so far: 20.200000000000003\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 13.0, 11.0, 11.0, 10.0, 13.0, 32.0, 33.0, 20.0, 20.0, 20.0, 21.0, 32.0, 33.0, 33.0, 30.0, 21.0, 42.0, 42.0, 36.0, 38.0, 43.0, 52.0, 46.0, 37.0, 45.0, 47.0, 46.0, 59.0, 39.0, 55.00000000000001, 50.0, 54.0, 53.0, 51.0, 47.0, 56.00000000000001, 57.99999999999999, 38.0, 53.0, 52.0, 47.0, 46.0, 51.0, 53.0, 77.0, 73.0, 71.0, 82.0, 67.0, 74.0, 85.0, 86.0, 70.0, 79.0, 86.0, 80.0, 79.0, 69.0, 80.0, 73.0, 84.0, 84.0, 74.0, 87.0, 86.0, 90.0, 85.0, 85.0, 90.0, 86.0, 94.0, 85.0, 72.0, 63.0, 70.0, 83.0, 88.0, 91.0, 93.0, 93.0, 93.0, 89.0, 89.0, 81.0, 78.0, 91.0, 94.0, 95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 96.0, 98.0, 97.0, 96.0, 95.0, 95.0, 99.0, 97.0, 96.0, 99.0, 97.0, 95.0, 97.0, 97.0, 98.0, 99.0, 100.0, 99.0, 99.0, 98.0, 99.0, 99.0, 98.0, 100.0, 100.0, 100.0, 96.0, 93.0, 99.0, 98.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.720720709637393, 0.03611510779138412, 7, 0.25652942986773136, 0.24065794312085842)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 1.0977, Accuracy (at final epoch): 7024/10000 (70%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [04:36<04:51, 58.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 1.8199, Accuracy (at final epoch): 6943/10000 (69%)\n","\n","Early stop, accuracy is 70\n","======================================\n","THIS IS ITERATION 5\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.04it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 27.900000000000002%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Found the value we wanted which is 27.900000000000002\n","\n","*****************************************************\n","Best accuracy after initial random search: 27.900000000000002\n","*****************************************************\n","Best validation errors: [9.8, 10.7, 9.8, 9.8, 10.7, 10.7, 9.8, 9.8, 10.7, 10.7, 9.8, 9.8, 9.8, 9.8, 9.8, 10.9, 9.8, 10.7, 10.7, 10.9, 10.7, 9.8, 9.8, 27.900000000000002, 9.8, 10.9, 10.7, 9.8, 10.7, 10.9]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 27.900000000000002\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 10.7\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 9.8\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 5.161444187164307.\n","=====================================================\n","======================================\n","Best accuracy so far: 27.900000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[34.0, 20.0, 22.0, 40.0, 42.0, 35.0, 54.0, 42.0, 48.0, 51.0, 44.0, 63.0, 57.99999999999999, 61.0, 65.0, 72.0, 55.00000000000001, 62.0, 68.0, 72.0, 75.0, 63.0, 73.0, 54.0, 51.0, 73.0, 71.0, 71.0, 76.0, 67.0, 69.0, 77.0, 87.0, 76.0, 83.0, 75.0, 81.0, 84.0, 85.0, 98.0, 82.0, 98.0, 95.0, 82.0, 96.0, 86.0, 75.0, 66.0, 87.0, 96.0, 97.0, 95.0, 97.0, 87.0, 88.0, 98.0, 89.0, 96.0, 99.0, 97.0, 97.0, 95.0, 98.0, 96.0, 94.0, 98.0, 93.0, 98.0, 97.0, 87.0, 98.0, 97.0, 100.0, 98.0, 100.0, 99.0, 99.0, 92.0, 76.0, 85.0, 99.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 98.0, 98.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 92.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 94.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.1319899192848664, 0.39568971808162556, 7, 0.5140819142971184, 0.1051857430290344)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 4.5022, Accuracy (at final epoch): 6861/10000 (69%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 5.8197, Accuracy (at final epoch): 6735/10000 (67%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 0 and max_accur is 68\n","\n","======================================\n","Stochastic hill-climbing iteration 1.\n","======================================\n","Best accuracy so far: 27.900000000000002\n","======================================\n","Best validation accuracy: 17.2%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 17.2\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 16.5%.\n","Best validation accuracy: 15.1%.\n","Best validation accuracy: 12.7%.\n","Best validation accuracy: 17.0%.\n","Best validation accuracy: 35.8%.\n","Best validation accuracy: 11.1%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 35.8\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 44.85620737075806.\n","=====================================================\n","======================================\n","Best accuracy so far: 35.8\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[22.0, 20.0, 32.0, 21.0, 22.0, 15.0, 17.0, 27.0, 19.0, 19.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 25.0, 43.0, 30.0, 25.0, 28.000000000000004, 35.0, 38.0, 44.0, 41.0, 24.0, 42.0, 49.0, 48.0, 42.0, 56.99999999999999, 48.0, 25.0, 37.0, 54.0, 56.99999999999999, 55.00000000000001, 55.00000000000001, 22.0, 44.0, 59.0, 63.0, 42.0, 55.00000000000001, 61.0, 40.0, 59.0, 65.0, 55.00000000000001, 66.0, 70.0, 37.0, 53.0, 52.0, 67.0, 77.0, 81.0, 84.0, 81.0, 82.0, 81.0, 80.0, 81.0, 83.0, 66.0, 80.0, 53.0, 84.0, 96.0, 95.0, 89.0, 87.0, 72.0, 61.0, 92.0, 97.0, 97.0, 96.0, 88.0, 74.0, 84.0, 86.0, 82.0, 86.0, 79.0, 81.0, 74.0, 90.0, 85.0, 72.0, 65.0, 88.0, 91.0, 86.0, 93.0, 95.0, 91.0, 89.0, 89.0, 87.0, 84.0, 86.0, 86.0, 90.0, 80.0, 76.0, 67.0, 70.0, 72.0, 73.0, 73.0, 86.0, 86.0, 78.0, 80.0, 79.0, 89.0, 89.0, 99.0, 100.0, 100.0, 94.0, 100.0, 97.0, 92.0, 95.0, 99.0, 97.0, 86.0, 89.0, 92.0, 91.0, 95.0, 86.0, 91.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 94.0, 95.0, 99.0, 100.0, 100.0, 96.0, 86.0, 72.0, 85.0, 90.0, 97.0, 100.0, 99.0, 100.0, 100.0, 99.0, 99.0, 99.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 96.0, 95.0, 98.0, 97.0, 96.0, 99.0, 100.0, 94.0, 89.0, 88.0, 86.0, 82.0, 91.0, 98.0, 100.0, 99.0, 98.0, 97.0, 95.0, 100.0, 100.0, 97.0, 97.0, 100.0, 94.0, 91.0, 96.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 94.0, 100.0, 100.0, 95.0, 97.0, 100.0, 100.0, 97.0, 95.0, 92.0, 87.0, 91.0, 84.0, 78.0, 91.0, 95.0, 91.0, 86.0, 91.0, 90.0, 97.0, 100.0, 97.0, 91.0, 87.0, 81.0, 80.0, 77.0, 93.0, 99.0, 86.0, 87.0, 90.0, 89.0, 93.0, 97.0, 98.0, 95.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 92.0, 95.0, 99.0, 98.0, 94.0, 98.0, 100.0, 100.0, 98.0, 93.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 97.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 98.0, 97.0, 99.0, 99.0, 99.0, 100.0, 100.0, 99.0, 91.0, 84.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 92.0, 89.0, 89.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 100.0, 100.0, 95.0, 94.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 98.0, 99.0, 100.0, 99.0, 98.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 97.0, 96.0, 95.0, 95.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(0.9047263675248817, 0.43690559600408013, 6, 0.7450728797621793, 0.07797012858680026)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 5.3847, Accuracy (at final epoch): 7229/10000 (72%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [06:06<04:31, 67.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 6.1988, Accuracy (at final epoch): 6912/10000 (69%)\n","\n","Early stop, accuracy is 72\n","======================================\n","THIS IS ITERATION 6\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:01,  4.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.40it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 4\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 5\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.47it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 6\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 17.5%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Found the value we wanted which is 17.5\n","\n","*****************************************************\n","Best accuracy after initial random search: 17.5\n","*****************************************************\n","Best validation errors: [9.8, 10.9, 9.8, 10.9, 10.7, 9.8, 10.9, 9.8, 9.8, 10.9, 9.8, 10.7, 10.7, 9.8, 10.9, 9.8, 10.7, 10.7, 9.8, 9.8, 9.8, 10.7, 10.7, 9.8, 9.8, 9.8, 9.8, 10.9, 9.8, 10.7, 10.7, 9.8, 9.8, 10.7, 9.8, 10.7, 9.8, 9.8, 10.9, 10.7, 9.8, 10.7, 10.7, 9.8, 9.8, 9.8, 10.7, 10.7, 10.9, 9.8, 10.9, 9.8, 17.5, 9.8, 10.7, 10.7, 9.8, 10.7, 10.7, 9.8]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 17.5\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 3.8556935787200928.\n","=====================================================\n","======================================\n","Best accuracy so far: 17.5\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 28.000000000000004, 33.0, 20.0, 20.0, 20.0, 22.0, 20.0, 20.0, 32.0, 20.0, 37.0, 43.0, 19.0, 42.0, 33.0, 31.0, 37.0, 28.000000000000004, 38.0, 32.0, 39.0, 38.0, 43.0, 36.0, 41.0, 37.0, 41.0, 40.0, 53.0, 51.0, 40.0, 54.0, 36.0, 39.0, 51.0, 57.99999999999999, 42.0, 48.0, 46.0, 55.00000000000001, 47.0, 44.0, 36.0, 50.0, 53.0, 39.0, 60.0, 47.0, 54.0, 52.0, 53.0, 55.00000000000001, 44.0, 64.0, 59.0, 67.0, 61.0, 66.0, 53.0, 64.0, 59.0, 64.0, 63.0, 56.99999999999999, 69.0, 59.0, 76.0, 63.0, 64.0, 64.0, 55.00000000000001, 69.0, 68.0, 71.0, 43.0, 76.0, 64.0, 74.0, 77.0, 74.0, 69.0, 78.0, 73.0, 80.0, 56.99999999999999, 75.0, 72.0, 64.0, 40.0, 83.0, 72.0, 86.0, 64.0, 88.0, 86.0, 88.0, 74.0, 76.0, 85.0, 90.0, 66.0, 82.0, 88.0, 87.0, 79.0, 70.0, 94.0, 79.0, 87.0, 95.0, 80.0, 74.0, 96.0, 96.0, 95.0, 96.0, 83.0, 71.0, 90.0, 91.0, 84.0, 100.0, 85.0, 73.0, 95.0, 84.0, 93.0, 85.0, 100.0, 87.0, 100.0, 89.0, 85.0, 95.0, 95.0, 96.0, 84.0, 100.0, 92.0, 100.0, 92.0, 85.0, 100.0, 98.0, 99.0, 95.0, 95.0, 99.0, 94.0, 98.0, 99.0, 100.0, 95.0, 89.0, 81.0, 100.0, 100.0, 99.0, 100.0, 100.0, 97.0, 100.0, 99.0, 98.0, 95.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 94.0, 94.0, 100.0, 100.0, 100.0, 99.0, 100.0, 93.0, 97.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 94.0, 100.0, 100.0, 99.0, 96.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 97.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(0.6823391042645667, 0.6491794159582256, 4, 0.2911272951542952, 0.008289922076585271)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 3.3348, Accuracy (at final epoch): 6904/10000 (69%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 4.1318, Accuracy (at final epoch): 6887/10000 (69%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 0 and max_accur is 69\n","\n","======================================\n","Stochastic hill-climbing iteration 1.\n","======================================\n","Best accuracy so far: 17.5\n","======================================\n","Best validation accuracy: 16.900000000000002%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 16.900000000000002\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 26.400000000000002%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.5%.\n","Best validation accuracy: 21.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 14.6%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 26.400000000000002\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 43.80294370651245.\n","=====================================================\n","======================================\n","Best accuracy so far: 26.400000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[14.000000000000002, 24.0, 34.0, 35.0, 32.0, 25.0, 33.0, 30.0, 33.0, 32.0, 39.0, 51.0, 43.0, 38.0, 28.000000000000004, 24.0, 38.0, 44.0, 45.0, 40.0, 36.0, 48.0, 48.0, 40.0, 36.0, 53.0, 56.99999999999999, 56.99999999999999, 56.00000000000001, 53.0, 54.0, 43.0, 54.0, 55.00000000000001, 68.0, 63.0, 41.0, 60.0, 60.0, 57.99999999999999, 77.0, 67.0, 54.0, 80.0, 68.0, 69.0, 53.0, 67.0, 80.0, 80.0, 80.0, 75.0, 95.0, 81.0, 80.0, 86.0, 88.0, 81.0, 61.0, 85.0, 79.0, 77.0, 90.0, 67.0, 41.0, 47.0, 66.0, 80.0, 84.0, 91.0, 86.0, 89.0, 89.0, 89.0, 95.0, 84.0, 92.0, 89.0, 95.0, 89.0, 93.0, 95.0, 96.0, 94.0, 89.0, 95.0, 95.0, 91.0, 94.0, 95.0, 92.0, 89.0, 95.0, 99.0, 98.0, 95.0, 95.0, 95.0, 95.0, 93.0, 99.0, 86.0, 91.0, 93.0, 97.0, 94.0, 88.0, 96.0, 99.0, 94.0, 98.0, 98.0, 96.0, 98.0, 98.0, 95.0, 96.0, 100.0, 97.0, 82.0, 91.0, 100.0, 97.0, 95.0, 83.0, 94.0, 91.0, 96.0, 100.0, 97.0, 100.0, 100.0, 99.0, 95.0, 99.0, 98.0, 90.0, 81.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 87.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 98.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 97.0, 96.0, 95.0, 95.0, 100.0, 100.0, 99.0, 95.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(0.9887688500297905, 0.7891532305943252, 7, 0.6751979829023456, 0.028516517062209337)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.7165, Accuracy (at final epoch): 7270/10000 (73%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [07:36<03:43, 74.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 8.6297, Accuracy (at final epoch): 7079/10000 (71%)\n","\n","Early stop, accuracy is 72\n","======================================\n","THIS IS ITERATION 7\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.24it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:01,  4.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:01,  4.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  4.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n","Best validation accuracy: 9.8%.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:00<00:01,  3.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  4.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 40.1%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:01<00:00,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Found the value we wanted which is 40.1\n","\n","*****************************************************\n","Best accuracy after initial random search: 40.1\n","*****************************************************\n","Best validation errors: [9.8, 9.8, 10.7, 9.8, 10.7, 10.9, 10.7, 9.8, 10.9, 10.7, 10.7, 9.8, 9.8, 9.8, 40.1, 9.8, 10.9, 9.8, 9.8, 10.7]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 40.1\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 15.2%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 20.3%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 20.3\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 11.799999999999999%.\n","Best validation accuracy: 20.599999999999998%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 18.0%.\n","Best validation accuracy: 11.3%.\n","Best validation accuracy: 12.4%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 20.599999999999998\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 3.460869550704956.\n","=====================================================\n","======================================\n","Best accuracy so far: 40.1\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[23.0, 63.0, 64.0, 56.00000000000001, 65.0, 57.99999999999999, 62.0, 63.0, 64.0, 67.0, 72.0, 76.0, 74.0, 80.0, 79.0, 86.0, 85.0, 91.0, 87.0, 86.0, 83.0, 83.0, 81.0, 92.0, 88.0, 85.0, 83.0, 96.0, 92.0, 90.0, 86.0, 94.0, 91.0, 86.0, 88.0, 85.0, 93.0, 91.0, 96.0, 95.0, 97.0, 97.0, 97.0, 93.0, 100.0, 99.0, 93.0, 93.0, 95.0, 96.0, 92.0, 95.0, 97.0, 94.0, 95.0, 98.0, 91.0, 100.0, 96.0, 98.0, 100.0, 100.0, 100.0, 99.0, 94.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5787313149481832, 0.27816312097721274, 3, 0.18460780454582154, 0.4335227313236569)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 0.8111, Accuracy (at final epoch): 7529/10000 (75%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [08:13<02:06, 63.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 1.4156, Accuracy (at final epoch): 7261/10000 (73%)\n","\n","Early stop, accuracy is 75\n","======================================\n","THIS IS ITERATION 8\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 25.2%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:01,  2.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:03<00:00,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  2.89it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Found the value we wanted which is 25.2\n","\n","*****************************************************\n","Best accuracy after initial random search: 25.2\n","*****************************************************\n","Best validation errors: [10.9, 10.7, 9.8, 10.7, 10.7, 25.2, 9.8, 9.8, 9.8, 9.8]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 25.2\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 21.2%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 19.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 33.5%.\n","***********************************************\n","Best accuracy after random mutation: 33.5\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 39.5%.\n","Best validation accuracy: 17.599999999999998%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 19.1%.\n","Best validation accuracy: 13.100000000000001%.\n","Best validation accuracy: 23.799999999999997%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 39.5\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 5.0956408977508545.\n","=====================================================\n","======================================\n","Best accuracy so far: 39.5\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[13.0, 48.0, 54.0, 50.0, 57.99999999999999, 71.0, 60.0, 57.99999999999999, 72.0, 76.0, 65.0, 74.0, 82.0, 87.0, 80.0, 76.0, 89.0, 89.0, 84.0, 83.0, 94.0, 87.0, 95.0, 91.0, 92.0, 97.0, 93.0, 99.0, 93.0, 94.0, 95.0, 99.0, 95.0, 99.0, 97.0, 97.0, 100.0, 100.0, 99.0, 99.0, 97.0, 99.0, 99.0, 99.0, 100.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.001, 6, 0.039020553276906525, 0.333166666663335)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 0.7842, Accuracy (at final epoch): 7590/10000 (76%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [09:00<00:58, 58.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 1.1664, Accuracy (at final epoch): 7468/10000 (75%)\n","\n","Early stop, accuracy is 75\n","======================================\n","THIS IS ITERATION 9\n","======================================\n","Back at the top of the while loop!, number of search times is 1\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 2\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:01<00:02,  2.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 3\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:02,  2.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 4\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:03,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.42it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 5\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  2.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:03<00:00,  2.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 6\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  2.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:01<00:02,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  2.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:03<00:00,  2.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 7\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.5%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  3.21it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 8\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.36it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 9\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:01,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:01<00:00,  3.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:02<00:00,  3.56it/s]\n","\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Not yet\n","\n","Back at the top of the while loop!, number of search times is 10\n","\n","Initital random search ...\n","Search iteration 1.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 1/10 [00:00<00:02,  4.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 2.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 20%|██        | 2/10 [00:00<00:02,  3.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Search iteration 3.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 30%|███       | 3/10 [00:00<00:02,  3.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 4.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 40%|████      | 4/10 [00:01<00:01,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.9%.\n","\n","Search iteration 5.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 50%|█████     | 5/10 [00:01<00:01,  3.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 6.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 60%|██████    | 6/10 [00:01<00:01,  3.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 7.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 70%|███████   | 7/10 [00:02<00:00,  3.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 8.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 80%|████████  | 8/10 [00:02<00:00,  3.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 9.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 90%|█████████ | 9/10 [00:02<00:00,  2.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 9.8%.\n","\n","Search iteration 10.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [00:03<00:00,  2.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.7%.\n","\n","Not yet\n","\n","*****************************************************\n","Best accuracy after initial random search: 10.9\n","*****************************************************\n","Best validation errors: [9.8, 10.7, 9.8, 9.8, 9.8, 10.7, 9.8, 10.5, 9.8, 9.8, 10.9, 10.9, 10.9, 10.7, 9.8, 10.7, 9.8, 10.9, 9.8, 9.8, 10.7, 10.7, 10.9, 10.7, 10.9, 10.7, 9.8, 9.8, 9.8, 10.7, 9.8, 10.7, 9.8, 10.9, 9.8, 10.9, 9.8, 9.8, 9.8, 10.7, 10.9, 9.8, 10.7, 9.8, 9.8, 10.9, 9.8, 10.9, 9.8, 9.8, 10.7, 9.8, 10.9, 10.9, 9.8, 9.8, 10.7, 10.9, 9.8, 9.8, 10.9, 10.9, 9.8, 9.8, 10.7, 10.5, 10.9, 10.7, 9.8, 10.7, 9.8, 9.8, 10.9, 10.9, 10.7, 10.7, 10.9, 9.8, 9.8, 9.8, 10.7, 10.9, 10.7, 9.8, 10.9, 9.8, 9.8, 9.8, 9.8, 10.9, 9.8, 10.7, 9.8, 10.9, 9.8, 9.8, 9.8, 9.8, 9.8, 10.7]\n","\n","======================================\n","Stochastic hill-climbing iteration 0.\n","======================================\n","Best accuracy so far: 10.9\n","======================================\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 34.8%.\n","***********************************************\n","Best accuracy after random mutation: 34.8\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 19.7%.\n","Best validation accuracy: 15.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 19.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 5.198202133178711.\n","=====================================================\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[34.0, 26.0, 24.0, 17.0, 19.0, 22.0, 48.0, 42.0, 39.0, 42.0, 39.0, 43.0, 36.0, 39.0, 33.0, 44.0, 44.0, 28.000000000000004, 13.0, 22.0, 11.0, 20.0, 33.0, 24.0, 13.0, 24.0, 17.0, 13.0, 33.0, 32.0, 33.0, 33.0, 33.0, 33.0, 32.0, 21.0, 41.0, 33.0, 39.0, 31.0, 33.0, 39.0, 36.0, 34.0, 37.0, 32.0, 30.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 27.0, 26.0, 23.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5345385862093677, 0.2468233253042169, 6, 0.99999999999001, 0.21461921015085847)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.1392, Accuracy (at final epoch): 2742/10000 (27%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.4618, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 0 and max_accur is 27\n","\n","======================================\n","Stochastic hill-climbing iteration 1.\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.6%.\n","Best validation accuracy: 11.799999999999999%.\n","***********************************************\n","Best accuracy after random mutation: 11.799999999999999\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 46.338852643966675.\n","=====================================================\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5345385862093677, 0.2468233253042169, 6, 0.99999999999001, 0.21461921015085847)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3893, Accuracy (at final epoch): 958/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.4170, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 1\n","\n","The shc reinitialization counter is 1\n","\n","Prev accuracy is 27 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 2.\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 19.400000000000002%.\n","***********************************************\n","Best accuracy after random mutation: 19.400000000000002\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 20.4%.\n","Best validation accuracy: 22.900000000000002%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Current learning rate: 0.10500000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 22.900000000000002\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 86.9465229511261.\n","=====================================================\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5345385862093677, 0.2468233253042169, 6, 0.99999999999001, 0.21461921015085847)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.4077, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3947, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 2\n","\n","The shc reinitialization counter is 2\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 3.\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.11000000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 127.9927384853363.\n","=====================================================\n","======================================\n","Best accuracy so far: 34.8\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5345385862093677, 0.2468233253042169, 6, 0.99999999999001, 0.21461921015085847)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3932, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3890, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 3\n","\n","The shc reinitialization counter is 3\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n","Picked from diff list\n","\n","******************************************************************************\n","The reinitialization counter is 0, changing chromosome\n","\n","Accuracy of this chromosome is 22.900000000000002\n","\n","The current move counter is 1\n","\n","******************************************************************************\n","======================================\n","Stochastic hill-climbing iteration 4.\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 169.86026668548584.\n","=====================================================\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[28.999999999999996, 32.0, 21.0, 23.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 23.0, 23.0, 15.0, 33.0, 13.0, 14.000000000000002, 20.0, 20.0, 38.0, 25.0, 14.000000000000002, 14.000000000000002, 12.0, 9.0, 10.0, 9.0, 10.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 6.0, 20.0, 20.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 21.0, 9.0, 10.0, 10.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 6.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 13.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 13.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 9.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 9.0, 9.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 9.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 6.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 6.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5628935749851716, 0.5486766157530306, 4, 0.99999999999001, 0.25355423980803526)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.1146, Accuracy (at final epoch): 2261/10000 (23%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 3.1326, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 10 and max_accur is 22\n","\n","======================================\n","Stochastic hill-climbing iteration 5.\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 18.4%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 18.4\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 30.2%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 30.2\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 208.9464967250824.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[31.0, 20.0, 20.0, 26.0, 34.0, 36.0, 28.999999999999996, 27.0, 32.0, 36.0, 36.0, 20.0, 32.0, 20.0, 18.0, 22.0, 36.0, 36.0, 40.0, 43.0, 40.0, 56.99999999999999, 60.0, 60.0, 63.0, 61.0, 73.0, 63.0, 56.00000000000001, 45.0, 70.0, 69.0, 66.0, 64.0, 80.0, 79.0, 84.0, 82.0, 73.0, 68.0, 59.0, 62.0, 56.99999999999999, 43.0, 40.0, 42.0, 42.0, 67.0, 68.0, 71.0, 68.0, 40.0, 47.0, 56.99999999999999, 56.00000000000001, 50.0, 57.99999999999999, 64.0, 68.0, 76.0, 76.0, 62.0, 56.99999999999999, 48.0, 65.0, 66.0, 70.0, 72.0, 54.0, 48.0, 47.0, 49.0, 77.0, 77.0, 73.0, 84.0, 81.0, 82.0, 85.0, 80.0, 85.0, 85.0, 82.0, 96.0, 94.0, 88.0, 87.0, 88.0, 78.0, 88.0, 85.0, 96.0, 91.0, 86.0, 84.0, 79.0, 79.0, 89.0, 90.0, 92.0, 92.0, 93.0, 93.0, 89.0, 90.0, 89.0, 89.0, 93.0, 92.0, 94.0, 90.0, 88.0, 82.0, 91.0, 92.0, 95.0, 94.0, 89.0, 89.0, 94.0, 95.0, 90.0, 84.0, 72.0, 66.0, 79.0, 78.0, 95.0, 85.0, 82.0, 87.0, 94.0, 85.0, 69.0, 57.99999999999999, 45.0, 68.0, 74.0, 83.0, 84.0, 86.0, 87.0, 85.0, 95.0, 89.0, 83.0, 87.0, 81.0, 88.0, 94.0, 88.0, 85.0, 92.0, 97.0, 94.0, 96.0, 89.0, 90.0, 93.0, 95.0, 95.0, 89.0, 95.0, 94.0, 94.0, 93.0, 95.0, 93.0, 95.0, 95.0, 95.0, 88.0, 89.0, 89.0, 95.0, 95.0, 96.0, 92.0, 95.0, 97.0, 97.0, 95.0, 95.0, 90.0, 96.0, 96.0, 95.0, 96.0, 97.0, 90.0, 88.0, 82.0, 92.0, 92.0, 96.0, 97.0, 98.0, 94.0, 91.0, 90.0, 93.0, 93.0, 96.0, 93.0, 93.0, 94.0, 94.0, 88.0, 88.0, 88.0, 85.0, 91.0, 91.0, 93.0, 92.0, 94.0, 90.0, 91.0, 90.0, 85.0, 92.0, 95.0, 94.0, 94.0, 95.0, 97.0, 92.0, 92.0, 94.0, 97.0, 95.0, 93.0, 90.0, 93.0, 93.0, 90.0, 91.0, 91.0, 97.0, 97.0, 99.0, 98.0, 83.0, 89.0, 90.0, 96.0, 95.0, 91.0, 95.0, 95.0, 95.0, 96.0, 98.0, 99.0, 98.0, 98.0, 95.0, 96.0, 99.0, 97.0, 98.0, 99.0, 99.0, 100.0, 98.0, 93.0, 87.0, 91.0, 91.0, 90.0, 91.0, 97.0, 99.0, 98.0, 98.0, 99.0, 96.0, 95.0, 98.0, 98.0, 98.0, 99.0, 95.0, 98.0, 98.0, 99.0, 99.0, 90.0, 99.0, 99.0, 99.0, 98.0, 98.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 97.0, 96.0, 98.0, 97.0, 99.0, 99.0, 99.0, 99.0, 99.0, 100.0, 100.0, 99.0, 99.0, 93.0, 99.0, 100.0, 99.0, 100.0, 100.0, 94.0, 92.0, 96.0, 100.0, 98.0, 98.0, 95.0, 95.0, 96.0, 97.0, 95.0, 97.0, 97.0, 96.0, 98.0, 97.0, 99.0, 98.0, 99.0, 97.0, 89.0, 91.0, 90.0, 92.0, 97.0, 98.0, 95.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 98.0, 98.0, 99.0, 97.0, 96.0, 79.0, 77.0, 91.0, 94.0, 94.0, 95.0, 94.0, 96.0, 96.0, 92.0, 97.0, 97.0, 98.0, 97.0, 98.0, 97.0, 97.0, 92.0, 93.0, 97.0, 100.0, 99.0, 96.0, 98.0, 98.0, 98.0, 99.0, 99.0, 92.0, 96.0, 96.0, 96.0, 93.0, 91.0, 98.0, 100.0, 98.0, 98.0, 99.0, 98.0, 98.0, 100.0, 96.0, 98.0, 98.0, 100.0, 100.0, 100.0, 98.0, 98.0, 100.0, 100.0, 98.0, 96.0, 96.0, 99.0, 99.0, 99.0, 100.0, 98.0, 91.0, 99.0, 99.0, 99.0, 95.0, 92.0, 97.0, 99.0, 97.0, 96.0, 98.0, 99.0, 100.0, 93.0, 96.0, 93.0, 95.0, 97.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 99.0, 98.0, 98.0, 99.0, 99.0, 99.0, 96.0, 95.0, 98.0, 99.0, 100.0, 98.0, 98.0, 99.0, 99.0, 100.0, 100.0, 100.0, 94.0, 91.0, 94.0, 100.0, 100.0, 100.0, 100.0, 99.0, 98.0, 99.0, 99.0, 100.0, 100.0, 99.0, 99.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0, 99.0, 94.0, 98.0, 100.0, 100.0, 100.0, 100.0, 100.0, 94.0, 94.0, 94.0, 98.0, 99.0, 100.0, 100.0, 99.0, 100.0, 99.0, 96.0, 98.0, 98.0, 97.0, 96.0, 99.0, 99.0, 98.0, 100.0, 97.0, 99.0, 100.0, 92.0, 96.0, 94.0, 94.0, 94.0, 100.0, 100.0, 87.0, 87.0, 100.0, 100.0, 100.0, 97.0, 96.0, 98.0, 100.0, 100.0, 100.0, 100.0, 99.0, 94.0, 99.0, 95.0, 98.0, 96.0, 96.0, 99.0, 99.0, 100.0, 100.0, 100.0, 96.0, 98.0, 100.0, 91.0, 88.0, 99.0, 100.0, 100.0, 100.0, 98.0, 97.0, 99.0, 94.0, 91.0, 93.0, 93.0, 86.0, 83.0, 89.0, 89.0, 96.0, 95.0, 94.0, 96.0, 92.0, 94.0, 94.0, 94.0, 91.0, 95.0, 91.0, 97.0, 96.0, 95.0, 95.0, 96.0, 95.0, 94.0, 94.0, 96.0, 95.0, 95.0, 96.0, 96.0, 95.0, 95.0, 96.0, 96.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 94.0, 95.0, 95.0, 95.0, 93.0, 93.0, 94.0, 88.0, 84.0, 84.0, 84.0, 89.0, 95.0, 84.0, 82.0, 81.0, 91.0, 84.0, 85.0, 91.0, 79.0, 88.0, 84.0, 84.0, 95.0, 95.0, 91.0, 91.0, 91.0, 95.0, 95.0, 95.0, 95.0, 95.0, 92.0, 94.0, 94.0, 94.0, 85.0, 84.0, 94.0, 88.0, 88.0, 94.0, 93.0, 94.0, 94.0, 94.0, 95.0, 91.0, 91.0, 91.0, 93.0, 95.0, 86.0, 83.0, 94.0, 95.0, 93.0, 91.0, 90.0, 89.0, 94.0, 94.0, 92.0, 92.0, 95.0, 95.0, 94.0, 92.0, 90.0, 87.0, 89.0, 87.0, 90.0, 89.0, 81.0, 78.0, 75.0, 78.0, 82.0, 81.0, 85.0, 90.0, 84.0, 91.0, 91.0, 83.0, 82.0, 79.0, 93.0, 89.0, 88.0, 87.0, 84.0, 84.0, 92.0, 94.0, 85.0, 85.0, 94.0, 93.0, 94.0, 94.0, 95.0, 93.0, 94.0, 95.0, 95.0, 93.0, 91.0, 90.0, 89.0, 84.0, 86.0, 95.0, 95.0, 94.0, 94.0, 92.0, 89.0, 88.0, 91.0, 93.0, 94.0, 93.0, 85.0, 90.0, 93.0, 94.0, 95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 94.0, 94.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 93.0, 97.0, 93.0, 92.0, 95.0, 94.0, 93.0, 75.0, 63.0, 82.0, 79.0, 91.0, 89.0, 87.0, 90.0, 91.0, 87.0, 90.0, 93.0, 94.0, 94.0, 89.0, 89.0, 90.0, 80.0, 92.0, 93.0, 93.0, 92.0, 92.0, 91.0, 89.0, 88.0, 88.0, 93.0, 89.0, 90.0, 94.0, 94.0, 91.0, 93.0, 97.0, 95.0, 95.0, 93.0, 93.0, 93.0, 93.0, 94.0, 89.0, 75.0, 93.0, 93.0, 93.0, 96.0, 94.0, 94.0, 93.0, 95.0, 92.0, 90.0, 87.0, 87.0, 93.0, 94.0, 94.0, 94.0, 88.0, 75.0, 75.0, 76.0, 79.0, 93.0, 93.0, 95.0, 95.0, 93.0, 91.0, 91.0, 91.0, 89.0, 94.0, 84.0, 93.0, 93.0, 88.0, 85.0, 85.0, 85.0, 92.0, 94.0, 95.0, 93.0, 95.0, 96.0, 76.0, 76.0, 77.0, 74.0, 73.0, 75.0, 86.0, 88.0, 91.0, 95.0, 95.0, 94.0, 95.0, 95.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 97.0, 92.0, 90.0, 89.0, 96.0, 93.0, 92.0, 92.0, 92.0, 96.0, 74.0, 71.0, 91.0, 92.0, 95.0, 94.0, 94.0, 94.0, 95.0, 95.0, 95.0, 96.0, 94.0, 94.0, 94.0, 94.0, 95.0, 94.0, 94.0, 94.0, 94.0, 95.0, 94.0, 94.0, 93.0, 91.0, 89.0, 92.0, 96.0, 97.0, 94.0, 86.0, 91.0, 91.0, 94.0, 94.0, 90.0, 89.0, 90.0, 95.0, 94.0, 93.0, 93.0, 97.0, 97.0, 97.0, 97.0, 96.0, 95.0, 78.0, 95.0, 93.0, 92.0, 93.0, 97.0, 95.0, 93.0, 95.0, 91.0, 91.0, 91.0, 91.0, 91.0, 92.0, 96.0, 91.0, 94.0, 95.0, 93.0, 93.0, 90.0, 91.0, 92.0, 88.0, 91.0, 95.0, 95.0, 92.0, 95.0, 95.0, 92.0, 97.0, 94.0, 93.0, 97.0, 92.0, 92.0, 94.0, 94.0, 94.0, 92.0, 91.0, 91.0, 91.0, 93.0, 95.0, 93.0, 93.0, 94.0, 94.0, 94.0, 79.0, 79.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.010905659142430215, 3, 0.8415766068525694, 0.6630314469458599)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 4.4586, Accuracy (at final epoch): 6319/10000 (63%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 34.9732, Accuracy (at final epoch): 5127/10000 (51%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 22 and max_accur is 63\n","\n","======================================\n","Stochastic hill-climbing iteration 6.\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 250.45595979690552.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[97.0, 97.0, 91.0, 75.0, 89.0, 95.0, 94.0, 97.0, 97.0, 97.0, 95.0, 95.0, 97.0, 97.0, 93.0, 94.0, 94.0, 95.0, 98.0, 95.0, 95.0, 98.0, 95.0, 93.0, 95.0, 95.0, 93.0, 93.0, 96.0, 96.0, 98.0, 98.0, 95.0, 95.0, 95.0, 95.0, 95.0, 98.0, 98.0, 98.0, 95.0, 94.0, 98.0, 98.0, 95.0, 98.0, 98.0, 96.0, 98.0, 97.0, 98.0, 95.0, 98.0, 98.0, 98.0, 98.0, 95.0, 95.0, 97.0, 98.0, 98.0, 98.0, 95.0, 95.0, 95.0, 95.0, 98.0, 98.0, 95.0, 93.0, 95.0, 98.0, 97.0, 98.0, 97.0, 93.0, 93.0, 97.0, 94.0, 92.0, 90.0, 90.0, 93.0, 97.0, 97.0, 96.0, 97.0, 94.0, 94.0, 97.0, 98.0, 97.0, 95.0, 92.0, 92.0, 94.0, 94.0, 93.0, 94.0, 88.0, 92.0, 92.0, 95.0, 95.0, 94.0, 95.0, 95.0, 95.0, 90.0, 90.0, 92.0, 96.0, 97.0, 97.0, 95.0, 95.0, 97.0, 97.0, 96.0, 95.0, 93.0, 93.0, 96.0, 97.0, 95.0, 95.0, 95.0, 94.0, 96.0, 96.0, 93.0, 93.0, 93.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 94.0, 93.0, 91.0, 92.0, 91.0, 90.0, 93.0, 92.0, 92.0, 88.0, 87.0, 83.0, 84.0, 85.0, 83.0, 83.0, 75.0, 74.0, 78.0, 76.0, 82.0, 79.0, 77.0, 84.0, 87.0, 85.0, 85.0, 76.0, 82.0, 81.0, 78.0, 83.0, 85.0, 84.0, 82.0, 82.0, 83.0, 79.0, 78.0, 83.0, 83.0, 75.0, 74.0, 83.0, 84.0, 82.0, 73.0, 71.0, 73.0, 72.0, 78.0, 83.0, 83.0, 74.0, 71.0, 80.0, 81.0, 82.0, 69.0, 80.0, 75.0, 83.0, 87.0, 79.0, 79.0, 76.0, 79.0, 81.0, 86.0, 74.0, 79.0, 79.0, 74.0, 81.0, 82.0, 80.0, 78.0, 73.0, 74.0, 86.0, 85.0, 76.0, 80.0, 80.0, 86.0, 86.0, 78.0, 78.0, 82.0, 82.0, 80.0, 77.0, 76.0, 74.0, 79.0, 80.0, 82.0, 80.0, 84.0, 85.0, 78.0, 79.0, 79.0, 83.0, 84.0, 85.0, 86.0, 80.0, 83.0, 83.0, 77.0, 82.0, 82.0, 87.0, 86.0, 88.0, 88.0, 86.0, 82.0, 84.0, 81.0, 83.0, 88.0, 88.0, 88.0, 82.0, 80.0, 76.0, 84.0, 85.0, 79.0, 77.0, 73.0, 84.0, 90.0, 82.0, 82.0, 89.0, 88.0, 88.0, 88.0, 83.0, 81.0, 81.0, 85.0, 85.0, 88.0, 84.0, 84.0, 88.0, 88.0, 84.0, 85.0, 86.0, 86.0, 82.0, 87.0, 85.0, 86.0, 86.0, 87.0, 88.0, 81.0, 81.0, 76.0, 69.0, 85.0, 84.0, 85.0, 85.0, 85.0, 88.0, 83.0, 80.0, 80.0, 81.0, 88.0, 87.0, 91.0, 92.0, 93.0, 88.0, 85.0, 82.0, 85.0, 89.0, 89.0, 88.0, 89.0, 88.0, 87.0, 92.0, 94.0, 95.0, 88.0, 86.0, 81.0, 89.0, 91.0, 92.0, 93.0, 93.0, 87.0, 87.0, 83.0, 89.0, 93.0, 96.0, 95.0, 90.0, 87.0, 89.0, 92.0, 91.0, 89.0, 94.0, 92.0, 97.0, 96.0, 96.0, 96.0, 92.0, 92.0, 90.0, 93.0, 93.0, 89.0, 93.0, 91.0, 91.0, 90.0, 90.0, 96.0, 96.0, 96.0, 92.0, 89.0, 82.0, 88.0, 89.0, 95.0, 95.0, 95.0, 89.0, 90.0, 90.0, 94.0, 94.0, 94.0, 92.0, 96.0, 94.0, 96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 91.0, 96.0, 92.0, 91.0, 96.0, 97.0, 93.0, 95.0, 97.0, 91.0, 94.0, 97.0, 96.0, 86.0, 85.0, 86.0, 89.0, 95.0, 96.0, 96.0, 95.0, 95.0, 90.0, 89.0, 89.0, 94.0, 91.0, 80.0, 96.0, 91.0, 91.0, 89.0, 92.0, 92.0, 95.0, 76.0, 74.0, 75.0, 92.0, 90.0, 95.0, 95.0, 95.0, 95.0, 96.0, 92.0, 96.0, 91.0, 94.0, 90.0, 85.0, 90.0, 90.0, 90.0, 93.0, 78.0, 90.0, 90.0, 91.0, 92.0, 91.0, 72.0, 78.0, 94.0, 96.0, 95.0, 95.0, 95.0, 92.0, 92.0, 90.0, 92.0, 91.0, 91.0, 92.0, 93.0, 92.0, 75.0, 77.0, 93.0, 90.0, 87.0, 87.0, 88.0, 93.0, 95.0, 94.0, 93.0, 75.0, 86.0, 90.0, 92.0, 94.0, 92.0, 94.0, 91.0, 88.0, 94.0, 91.0, 93.0, 93.0, 90.0, 92.0, 91.0, 91.0, 95.0, 96.0, 93.0, 95.0, 96.0, 93.0, 93.0, 97.0, 97.0, 92.0, 92.0, 91.0, 92.0, 93.0, 97.0, 95.0, 97.0, 94.0, 94.0, 94.0, 90.0, 93.0, 97.0, 97.0, 92.0, 91.0, 95.0, 95.0, 96.0, 96.0, 97.0, 96.0, 93.0, 92.0, 92.0, 97.0, 97.0, 93.0, 98.0, 93.0, 93.0, 98.0, 97.0, 98.0, 93.0, 94.0, 92.0, 97.0, 97.0, 97.0, 97.0, 97.0, 92.0, 92.0, 93.0, 93.0, 98.0, 92.0, 91.0, 97.0, 97.0, 98.0, 98.0, 98.0, 93.0, 93.0, 98.0, 98.0, 98.0, 93.0, 98.0, 98.0, 93.0, 93.0, 93.0, 98.0, 95.0, 94.0, 95.0, 93.0, 95.0, 90.0, 91.0, 92.0, 97.0, 93.0, 98.0, 97.0, 97.0, 93.0, 92.0, 92.0, 95.0, 96.0, 78.0, 77.0, 87.0, 88.0, 89.0, 89.0, 96.0, 96.0, 96.0, 97.0, 91.0, 69.0, 86.0, 88.0, 90.0, 89.0, 89.0, 89.0, 94.0, 94.0, 77.0, 93.0, 94.0, 88.0, 81.0, 83.0, 88.0, 87.0, 75.0, 73.0, 87.0, 84.0, 94.0, 89.0, 94.0, 86.0, 72.0, 89.0, 81.0, 87.0, 95.0, 95.0, 94.0, 89.0, 88.0, 87.0, 93.0, 94.0, 93.0, 94.0, 94.0, 91.0, 94.0, 77.0, 77.0, 83.0, 83.0, 88.0, 94.0, 94.0, 94.0, 94.0, 89.0, 89.0, 84.0, 94.0, 93.0, 94.0, 95.0, 95.0, 90.0, 71.0, 71.0, 71.0, 88.0, 88.0, 89.0, 76.0, 72.0, 73.0, 93.0, 90.0, 95.0, 93.0, 72.0, 67.0, 87.0, 92.0, 92.0, 87.0, 87.0, 87.0, 88.0, 92.0, 92.0, 72.0, 84.0, 86.0, 86.0, 89.0, 90.0, 92.0, 87.0, 89.0, 92.0, 92.0, 88.0, 89.0, 90.0, 87.0, 92.0, 72.0, 90.0, 89.0, 89.0, 92.0, 92.0, 85.0, 85.0, 73.0, 90.0, 89.0, 89.0, 92.0, 90.0, 87.0, 85.0, 89.0, 79.0, 95.0, 93.0, 95.0, 95.0, 90.0, 88.0, 88.0, 93.0, 94.0, 94.0, 90.0, 90.0, 93.0, 95.0, 95.0, 90.0, 90.0, 95.0, 93.0, 93.0, 95.0, 95.0, 77.0, 95.0, 95.0, 88.0, 72.0, 93.0, 93.0, 95.0, 90.0, 89.0, 88.0, 92.0, 92.0, 94.0, 95.0, 95.0, 90.0, 90.0, 93.0, 93.0, 75.0, 75.0, 93.0, 95.0, 95.0, 93.0, 95.0, 95.0, 93.0, 93.0, 93.0, 91.0, 95.0, 95.0, 95.0, 90.0, 90.0, 88.0, 88.0, 88.0, 95.0, 95.0, 93.0, 94.0, 95.0, 93.0, 87.0, 87.0, 88.0, 90.0, 91.0, 91.0, 91.0, 95.0, 95.0, 95.0, 90.0, 72.0, 90.0, 90.0, 93.0, 93.0, 95.0, 95.0, 95.0, 76.0, 77.0, 90.0, 95.0, 93.0, 93.0, 93.0, 95.0, 95.0, 72.0, 72.0, 90.0, 92.0, 94.0, 94.0, 94.0, 94.0, 94.0, 88.0, 87.0, 92.0, 94.0, 93.0, 94.0, 94.0, 90.0, 85.0, 87.0, 92.0, 94.0, 94.0, 93.0, 92.0, 94.0, 89.0, 86.0, 92.0, 95.0, 95.0, 95.0, 90.0, 89.0, 88.0, 95.0, 77.0, 95.0, 95.0, 95.0, 93.0, 88.0, 88.0, 71.0, 76.0, 76.0, 94.0, 94.0, 90.0, 68.0, 86.0, 90.0, 92.0, 86.0, 90.0, 92.0, 95.0, 93.0, 93.0, 95.0, 88.0, 90.0, 93.0, 77.0, 76.0, 72.0, 95.0, 95.0, 93.0, 93.0, 93.0, 95.0, 95.0, 71.0, 89.0, 90.0, 90.0, 95.0, 91.0, 91.0, 70.0, 69.0, 88.0, 90.0, 95.0, 95.0, 93.0, 69.0, 69.0, 88.0, 93.0, 91.0, 91.0, 90.0, 89.0, 89.0, 95.0, 95.0, 91.0, 93.0, 91.0, 91.0, 73.0, 73.0, 93.0, 93.0, 93.0, 94.0, 90.0, 90.0, 94.0, 73.0, 74.0, 91.0, 92.0, 87.0, 92.0, 93.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 90.0, 90.0, 92.0, 92.0, 92.0, 92.0, 90.0, 93.0, 93.0, 70.0, 90.0, 92.0, 92.0, 90.0, 90.0, 90.0, 88.0, 88.0, 87.0, 85.0, 77.0, 92.0, 90.0, 88.0, 88.0, 93.0, 95.0, 95.0, 90.0, 90.0, 93.0, 93.0, 76.0, 93.0, 93.0, 94.0, 94.0, 89.0, 70.0, 87.0, 90.0, 90.0, 95.0, 75.0, 92.0, 95.0, 95.0, 88.0, 70.0, 88.0, 90.0, 95.0, 93.0, 95.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.010905659142430215, 3, 0.8415766068525694, 0.6630314469458599)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 31.8420, Accuracy (at final epoch): 5521/10000 (55%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 24.5414, Accuracy (at final epoch): 5380/10000 (54%)\n","\n","Diff counter is 1\n","\n","The shc reinitialization counter is 1\n","\n","Prev accuracy is 63 and max_accur is 55\n","\n","======================================\n","Stochastic hill-climbing iteration 7.\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 29.9%.\n","Best validation accuracy: 10.9%.\n","***********************************************\n","Best accuracy after random mutation: 29.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 28.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.10500000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 28.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 292.10990834236145.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[95.0, 90.0, 77.0, 76.0, 95.0, 86.0, 93.0, 95.0, 87.0, 92.0, 93.0, 90.0, 95.0, 95.0, 88.0, 75.0, 93.0, 95.0, 95.0, 90.0, 95.0, 93.0, 77.0, 93.0, 95.0, 90.0, 95.0, 93.0, 95.0, 95.0, 77.0, 93.0, 90.0, 90.0, 93.0, 95.0, 95.0, 70.0, 70.0, 70.0, 90.0, 90.0, 90.0, 90.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 88.0, 88.0, 90.0, 77.0, 77.0, 95.0, 95.0, 93.0, 93.0, 88.0, 88.0, 90.0, 95.0, 95.0, 73.0, 93.0, 86.0, 90.0, 95.0, 77.0, 93.0, 93.0, 95.0, 95.0, 90.0, 95.0, 93.0, 93.0, 88.0, 90.0, 90.0, 90.0, 90.0, 91.0, 95.0, 93.0, 95.0, 71.0, 70.0, 70.0, 95.0, 93.0, 88.0, 93.0, 93.0, 95.0, 76.0, 95.0, 95.0, 86.0, 86.0, 93.0, 75.0, 95.0, 95.0, 95.0, 95.0, 95.0, 75.0, 93.0, 93.0, 93.0, 90.0, 95.0, 95.0, 95.0, 75.0, 75.0, 93.0, 88.0, 86.0, 95.0, 79.0, 95.0, 93.0, 93.0, 70.0, 88.0, 83.0, 88.0, 88.0, 88.0, 93.0, 93.0, 95.0, 95.0, 93.0, 93.0, 93.0, 89.0, 95.0, 93.0, 93.0, 95.0, 77.0, 95.0, 95.0, 90.0, 90.0, 90.0, 69.0, 90.0, 95.0, 95.0, 93.0, 95.0, 88.0, 93.0, 95.0, 95.0, 70.0, 70.0, 88.0, 88.0, 95.0, 95.0, 95.0, 90.0, 90.0, 75.0, 95.0, 95.0, 93.0, 93.0, 95.0, 90.0, 71.0, 89.0, 90.0, 95.0, 95.0, 93.0, 88.0, 93.0, 91.0, 91.0, 95.0, 95.0, 70.0, 70.0, 88.0, 88.0, 90.0, 95.0, 93.0, 75.0, 95.0, 88.0, 93.0, 93.0, 93.0, 95.0, 95.0, 93.0, 93.0, 90.0, 90.0, 90.0, 95.0, 95.0, 93.0, 95.0, 95.0, 95.0, 77.0, 90.0, 93.0, 93.0, 87.0, 89.0, 90.0, 95.0, 95.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 87.0, 88.0, 95.0, 95.0, 88.0, 88.0, 95.0, 95.0, 90.0, 88.0, 93.0, 95.0, 90.0, 90.0, 95.0, 93.0, 88.0, 95.0, 95.0, 95.0, 90.0, 93.0, 95.0, 93.0, 90.0, 75.0, 93.0, 90.0, 95.0, 93.0, 93.0, 93.0, 90.0, 95.0, 95.0, 93.0, 75.0, 75.0, 88.0, 86.0, 91.0, 91.0, 72.0, 90.0, 95.0, 95.0, 86.0, 75.0, 93.0, 93.0, 95.0, 95.0, 90.0, 70.0, 76.0, 95.0, 95.0, 73.0, 70.0, 88.0, 86.0, 91.0, 91.0, 90.0, 95.0, 75.0, 75.0, 75.0, 76.0, 95.0, 91.0, 95.0, 95.0, 88.0, 75.0, 93.0, 95.0, 93.0, 95.0, 95.0, 95.0, 95.0, 86.0, 86.0, 95.0, 93.0, 93.0, 95.0, 93.0, 92.0, 95.0, 95.0, 90.0, 88.0, 93.0, 95.0, 95.0, 87.0, 88.0, 88.0, 93.0, 93.0, 95.0, 87.0, 87.0, 95.0, 95.0, 93.0, 93.0, 88.0, 95.0, 75.0, 89.0, 93.0, 95.0, 95.0, 94.0, 73.0, 90.0, 88.0, 88.0, 95.0, 95.0, 95.0, 95.0, 93.0, 88.0, 88.0, 93.0, 95.0, 95.0, 95.0, 69.0, 69.0, 88.0, 95.0, 95.0, 71.0, 70.0, 71.0, 88.0, 88.0, 93.0, 93.0, 95.0, 90.0, 88.0, 90.0, 90.0, 90.0, 95.0, 93.0, 93.0, 76.0, 77.0, 90.0, 90.0, 90.0, 95.0, 95.0, 93.0, 87.0, 88.0, 95.0, 95.0, 70.0, 70.0, 88.0, 88.0, 91.0, 86.0, 91.0, 91.0, 93.0, 93.0, 72.0, 89.0, 89.0, 93.0, 93.0, 95.0, 95.0, 95.0, 90.0, 75.0, 75.0, 93.0, 93.0, 91.0, 93.0, 88.0, 71.0, 88.0, 93.0, 95.0, 95.0, 90.0, 90.0, 72.0, 75.0, 90.0, 86.0, 86.0, 88.0, 92.0, 93.0, 75.0, 95.0, 95.0, 93.0, 91.0, 91.0, 93.0, 95.0, 95.0, 93.0, 93.0, 75.0, 93.0, 93.0, 95.0, 95.0, 90.0, 88.0, 70.0, 90.0, 95.0, 95.0, 95.0, 90.0, 95.0, 93.0, 95.0, 93.0, 95.0, 70.0, 90.0, 90.0, 93.0, 93.0, 93.0, 95.0, 90.0, 70.0, 88.0, 93.0, 93.0, 95.0, 94.0, 90.0, 90.0, 95.0, 75.0, 75.0, 91.0, 91.0, 93.0, 93.0, 90.0, 77.0, 95.0, 90.0, 90.0, 93.0, 93.0, 93.0, 95.0, 95.0, 90.0, 69.0, 75.0, 93.0, 93.0, 95.0, 90.0, 95.0, 95.0, 95.0, 95.0, 93.0, 69.0, 75.0, 88.0, 95.0, 90.0, 95.0, 95.0, 86.0, 70.0, 87.0, 88.0, 93.0, 95.0, 95.0, 95.0, 93.0, 71.0, 72.0, 95.0, 95.0, 95.0, 90.0, 75.0, 75.0, 93.0, 88.0, 88.0, 90.0, 95.0, 76.0, 77.0, 93.0, 90.0, 95.0, 95.0, 95.0, 93.0, 93.0, 95.0, 95.0, 94.0, 95.0, 88.0, 93.0, 95.0, 95.0, 90.0, 95.0, 95.0, 93.0, 88.0, 95.0, 93.0, 72.0, 72.0, 95.0, 93.0, 88.0, 93.0, 93.0, 77.0, 95.0, 95.0, 90.0, 87.0, 93.0, 95.0, 95.0, 87.0, 88.0, 95.0, 93.0, 95.0, 90.0, 95.0, 90.0, 90.0, 74.0, 92.0, 86.0, 88.0, 90.0, 90.0, 93.0, 75.0, 75.0, 75.0, 75.0, 93.0, 93.0, 95.0, 95.0, 95.0, 69.0, 88.0, 88.0, 88.0, 93.0, 95.0, 95.0, 95.0, 72.0, 93.0, 90.0, 95.0, 95.0, 93.0, 93.0, 93.0, 90.0, 89.0, 95.0, 77.0, 94.0, 90.0, 90.0, 93.0, 95.0, 95.0, 89.0, 90.0, 93.0, 95.0, 95.0, 88.0, 89.0, 72.0, 77.0, 94.0, 95.0, 95.0, 88.0, 93.0, 93.0, 77.0, 90.0, 93.0, 95.0, 93.0, 88.0, 90.0, 95.0, 93.0, 93.0, 95.0, 89.0, 90.0, 93.0, 93.0, 95.0, 95.0, 90.0, 95.0, 75.0, 75.0, 93.0, 93.0, 95.0, 90.0, 95.0, 95.0, 90.0, 67.0, 86.0, 90.0, 90.0, 95.0, 93.0, 95.0, 71.0, 89.0, 90.0, 95.0, 93.0, 93.0, 93.0, 88.0, 71.0, 90.0, 95.0, 93.0, 93.0, 95.0, 95.0, 95.0, 90.0, 72.0, 69.0, 69.0, 86.0, 86.0, 91.0, 95.0, 90.0, 90.0, 90.0, 95.0, 95.0, 93.0, 69.0, 69.0, 87.0, 88.0, 93.0, 91.0, 91.0, 91.0, 77.0, 76.0, 76.0, 70.0, 72.0, 76.0, 78.0, 95.0, 95.0, 90.0, 95.0, 77.0, 95.0, 90.0, 93.0, 93.0, 95.0, 95.0, 88.0, 69.0, 74.0, 95.0, 90.0, 90.0, 86.0, 87.0, 74.0, 74.0, 72.0, 86.0, 90.0, 90.0, 76.0, 76.0, 70.0, 90.0, 90.0, 88.0, 74.0, 74.0, 93.0, 88.0, 95.0, 95.0, 72.0, 90.0, 88.0, 88.0, 88.0, 93.0, 93.0, 95.0, 95.0, 95.0, 75.0, 70.0, 88.0, 86.0, 86.0, 71.0, 95.0, 93.0, 93.0, 93.0, 93.0, 89.0, 95.0, 95.0, 95.0, 93.0, 75.0, 75.0, 88.0, 93.0, 95.0, 95.0, 95.0, 93.0, 93.0, 93.0, 88.0, 91.0, 91.0, 91.0, 88.0, 95.0, 95.0, 95.0, 93.0, 95.0, 95.0, 95.0, 95.0, 95.0, 90.0, 90.0, 90.0, 90.0, 93.0, 91.0, 95.0, 95.0, 89.0, 95.0, 95.0, 78.0, 93.0, 88.0, 86.0, 95.0, 93.0, 93.0, 95.0, 95.0, 78.0, 95.0, 90.0, 90.0, 95.0, 95.0, 93.0, 76.0, 93.0, 95.0, 95.0, 95.0, 95.0, 93.0, 93.0, 86.0, 91.0, 95.0, 95.0, 95.0, 94.0, 75.0, 76.0, 95.0, 95.0, 95.0, 93.0, 92.0, 92.0, 87.0, 86.0, 87.0, 87.0, 93.0, 93.0, 89.0, 89.0, 86.0, 87.0, 87.0, 89.0, 89.0, 88.0, 93.0, 92.0, 92.0, 93.0, 91.0, 91.0, 93.0, 92.0, 90.0, 92.0, 90.0, 91.0, 93.0, 95.0, 95.0, 95.0, 84.0, 67.0, 74.0, 91.0, 93.0, 93.0, 93.0, 93.0, 88.0, 74.0, 87.0, 89.0, 90.0, 76.0, 90.0, 75.0, 93.0, 90.0, 90.0, 90.0, 90.0, 95.0, 88.0, 92.0, 93.0, 93.0, 89.0, 95.0, 95.0, 75.0, 70.0, 70.0, 86.0, 86.0, 74.0, 72.0, 76.0, 95.0, 90.0, 95.0, 76.0, 93.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 90.0, 95.0, 95.0, 95.0, 89.0, 87.0, 87.0, 86.0, 86.0, 91.0, 89.0, 77.0, 91.0, 95.0, 77.0, 95.0, 86.0, 87.0, 95.0, 95.0, 89.0, 86.0, 95.0, 95.0, 93.0, 75.0, 76.0, 93.0, 95.0, 90.0, 95.0, 95.0, 95.0, 87.0, 90.0, 95.0, 95.0, 95.0, 75.0, 88.0, 88.0, 90.0, 90.0, 90.0, 95.0, 77.0, 77.0, 95.0, 95.0, 92.0, 91.0, 93.0, 88.0, 95.0, 77.0, 77.0, 95.0, 95.0, 93.0, 90.0, 88.0, 88.0, 88.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.010905659142430215, 3, 0.8415766068525694, 0.6630314469458599)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 23.3519, Accuracy (at final epoch): 5416/10000 (54%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 50.1074, Accuracy (at final epoch): 4649/10000 (46%)\n","\n","Diff counter is 2\n","\n","The shc reinitialization counter is 2\n","\n","Prev accuracy is 55 and max_accur is 54\n","\n","======================================\n","Stochastic hill-climbing iteration 8.\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 19.8%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 19.8\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.11000000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 333.7013313770294.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.2\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[86.0, 93.0, 93.0, 93.0, 93.0, 88.0, 90.0, 95.0, 95.0, 75.0, 93.0, 93.0, 91.0, 95.0, 95.0, 95.0, 75.0, 75.0, 87.0, 90.0, 95.0, 76.0, 95.0, 95.0, 90.0, 88.0, 93.0, 93.0, 94.0, 77.0, 95.0, 95.0, 95.0, 70.0, 69.0, 86.0, 86.0, 86.0, 88.0, 73.0, 74.0, 91.0, 71.0, 89.0, 90.0, 95.0, 93.0, 93.0, 95.0, 93.0, 74.0, 93.0, 93.0, 93.0, 95.0, 95.0, 90.0, 95.0, 91.0, 91.0, 77.0, 94.0, 95.0, 91.0, 91.0, 95.0, 76.0, 75.0, 70.0, 88.0, 93.0, 95.0, 90.0, 90.0, 90.0, 90.0, 90.0, 95.0, 95.0, 93.0, 93.0, 93.0, 95.0, 95.0, 90.0, 90.0, 95.0, 95.0, 95.0, 69.0, 69.0, 90.0, 86.0, 74.0, 72.0, 76.0, 95.0, 90.0, 75.0, 75.0, 93.0, 88.0, 88.0, 95.0, 95.0, 90.0, 90.0, 91.0, 75.0, 77.0, 91.0, 91.0, 95.0, 90.0, 88.0, 75.0, 75.0, 75.0, 75.0, 77.0, 95.0, 91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 95.0, 95.0, 93.0, 93.0, 93.0, 92.0, 88.0, 90.0, 95.0, 77.0, 75.0, 69.0, 69.0, 88.0, 88.0, 88.0, 95.0, 94.0, 95.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 75.0, 69.0, 69.0, 86.0, 91.0, 89.0, 86.0, 91.0, 87.0, 70.0, 71.0, 89.0, 87.0, 88.0, 86.0, 86.0, 86.0, 91.0, 89.0, 89.0, 95.0, 91.0, 91.0, 89.0, 87.0, 95.0, 95.0, 95.0, 95.0, 91.0, 90.0, 94.0, 86.0, 86.0, 95.0, 77.0, 91.0, 91.0, 93.0, 93.0, 90.0, 89.0, 89.0, 77.0, 91.0, 91.0, 91.0, 86.0, 72.0, 77.0, 95.0, 95.0, 86.0, 86.0, 88.0, 69.0, 74.0, 76.0, 90.0, 90.0, 90.0, 70.0, 74.0, 74.0, 74.0, 93.0, 88.0, 90.0, 90.0, 95.0, 76.0, 91.0, 91.0, 77.0, 71.0, 88.0, 93.0, 93.0, 95.0, 93.0, 93.0, 77.0, 71.0, 89.0, 90.0, 90.0, 88.0, 75.0, 91.0, 91.0, 93.0, 95.0, 95.0, 95.0, 89.0, 90.0, 95.0, 94.0, 75.0, 93.0, 86.0, 91.0, 91.0, 93.0, 95.0, 89.0, 90.0, 71.0, 95.0, 93.0, 95.0, 95.0, 95.0, 90.0, 90.0, 95.0, 93.0, 93.0, 93.0, 93.0, 95.0, 90.0, 72.0, 94.0, 77.0, 85.0, 68.0, 91.0, 91.0, 86.0, 90.0, 90.0, 90.0, 95.0, 75.0, 69.0, 87.0, 88.0, 93.0, 93.0, 93.0, 95.0, 71.0, 89.0, 90.0, 93.0, 93.0, 93.0, 93.0, 93.0, 90.0, 90.0, 95.0, 77.0, 95.0, 78.0, 71.0, 88.0, 88.0, 88.0, 93.0, 93.0, 73.0, 90.0, 90.0, 95.0, 95.0, 95.0, 93.0, 88.0, 88.0, 93.0, 95.0, 95.0, 72.0, 68.0, 86.0, 86.0, 86.0, 91.0, 73.0, 89.0, 89.0, 91.0, 86.0, 87.0, 89.0, 91.0, 91.0, 91.0, 91.0, 86.0, 89.0, 89.0, 91.0, 75.0, 93.0, 91.0, 88.0, 95.0, 90.0, 89.0, 72.0, 72.0, 90.0, 95.0, 93.0, 93.0, 93.0, 93.0, 95.0, 90.0, 90.0, 77.0, 95.0, 95.0, 78.0, 76.0, 93.0, 93.0, 86.0, 89.0, 89.0, 89.0, 95.0, 95.0, 95.0, 75.0, 69.0, 93.0, 91.0, 91.0, 95.0, 95.0, 89.0, 89.0, 89.0, 90.0, 90.0, 88.0, 75.0, 88.0, 91.0, 90.0, 94.0, 93.0, 90.0, 72.0, 75.0, 76.0, 78.0, 77.0, 77.0, 95.0, 95.0, 75.0, 77.0, 77.0, 95.0, 95.0, 86.0, 86.0, 91.0, 91.0, 91.0, 91.0, 91.0, 94.0, 89.0, 89.0, 93.0, 93.0, 95.0, 95.0, 95.0, 94.0, 75.0, 88.0, 88.0, 95.0, 95.0, 72.0, 88.0, 88.0, 95.0, 95.0, 95.0, 95.0, 95.0, 86.0, 90.0, 95.0, 76.0, 74.0, 70.0, 88.0, 86.0, 86.0, 90.0, 94.0, 76.0, 76.0, 75.0, 93.0, 90.0, 89.0, 89.0, 95.0, 75.0, 75.0, 93.0, 91.0, 91.0, 91.0, 91.0, 76.0, 76.0, 93.0, 93.0, 90.0, 90.0, 95.0, 78.0, 76.0, 93.0, 95.0, 95.0, 90.0, 90.0, 78.0, 77.0, 77.0, 86.0, 91.0, 91.0, 91.0, 76.0, 76.0, 95.0, 95.0, 90.0, 90.0, 90.0, 88.0, 93.0, 93.0, 77.0, 69.0, 74.0, 70.0, 88.0, 95.0, 77.0, 77.0, 95.0, 88.0, 93.0, 90.0, 75.0, 75.0, 95.0, 93.0, 95.0, 90.0, 95.0, 90.0, 93.0, 93.0, 93.0, 95.0, 95.0, 69.0, 69.0, 88.0, 86.0, 86.0, 93.0, 94.0, 77.0, 70.0, 69.0, 69.0, 93.0, 95.0, 95.0, 88.0, 87.0, 75.0, 87.0, 93.0, 95.0, 95.0, 70.0, 70.0, 69.0, 69.0, 70.0, 86.0, 91.0, 91.0, 91.0, 95.0, 71.0, 89.0, 89.0, 95.0, 75.0, 75.0, 93.0, 93.0, 93.0, 93.0, 95.0, 78.0, 72.0, 70.0, 70.0, 71.0, 90.0, 90.0, 93.0, 74.0, 74.0, 72.0, 72.0, 76.0, 71.0, 90.0, 95.0, 95.0, 93.0, 93.0, 85.0, 86.0, 90.0, 95.0, 95.0, 75.0, 93.0, 93.0, 93.0, 93.0, 95.0, 95.0, 95.0, 95.0, 95.0, 90.0, 95.0, 77.0, 75.0, 75.0, 93.0, 86.0, 86.0, 93.0, 75.0, 76.0, 93.0, 77.0, 78.0, 90.0, 95.0, 93.0, 93.0, 95.0, 75.0, 90.0, 95.0, 95.0, 95.0, 95.0, 94.0, 95.0, 95.0, 95.0, 93.0, 93.0, 93.0, 95.0, 95.0, 77.0, 88.0, 88.0, 88.0, 95.0, 95.0, 90.0, 95.0, 93.0, 93.0, 93.0, 93.0, 89.0, 89.0, 95.0, 95.0, 95.0, 87.0, 93.0, 95.0, 90.0, 90.0, 95.0, 95.0, 75.0, 73.0, 69.0, 86.0, 86.0, 86.0, 86.0, 73.0, 73.0, 90.0, 88.0, 69.0, 69.0, 69.0, 93.0, 95.0, 95.0, 89.0, 95.0, 95.0, 75.0, 70.0, 88.0, 88.0, 93.0, 91.0, 86.0, 86.0, 92.0, 92.0, 88.0, 88.0, 88.0, 88.0, 90.0, 90.0, 91.0, 91.0, 88.0, 87.0, 87.0, 89.0, 94.0, 94.0, 86.0, 88.0, 91.0, 91.0, 93.0, 93.0, 76.0, 86.0, 89.0, 93.0, 94.0, 93.0, 93.0, 89.0, 89.0, 94.0, 91.0, 91.0, 93.0, 94.0, 88.0, 88.0, 89.0, 88.0, 94.0, 88.0, 94.0, 94.0, 94.0, 89.0, 89.0, 94.0, 93.0, 93.0, 88.0, 86.0, 91.0, 90.0, 85.0, 88.0, 87.0, 87.0, 88.0, 90.0, 91.0, 91.0, 87.0, 87.0, 93.0, 94.0, 90.0, 90.0, 90.0, 86.0, 85.0, 85.0, 87.0, 90.0, 88.0, 88.0, 88.0, 90.0, 86.0, 87.0, 93.0, 94.0, 90.0, 88.0, 86.0, 86.0, 90.0, 85.0, 87.0, 87.0, 88.0, 90.0, 90.0, 90.0, 86.0, 87.0, 90.0, 88.0, 88.0, 88.0, 87.0, 93.0, 94.0, 90.0, 90.0, 94.0, 85.0, 91.0, 89.0, 89.0, 86.0, 87.0, 93.0, 93.0, 87.0, 88.0, 86.0, 91.0, 94.0, 93.0, 89.0, 89.0, 94.0, 93.0, 86.0, 86.0, 94.0, 94.0, 94.0, 91.0, 93.0, 93.0, 88.0, 89.0, 91.0, 89.0, 91.0, 86.0, 91.0, 86.0, 86.0, 86.0, 75.0, 72.0, 72.0, 76.0, 90.0, 86.0, 86.0, 89.0, 76.0, 76.0, 76.0, 76.0, 90.0, 90.0, 86.0, 88.0, 76.0, 90.0, 90.0, 76.0, 74.0, 75.0, 93.0, 88.0, 88.0, 90.0, 95.0, 93.0, 77.0, 69.0, 71.0, 71.0, 95.0, 95.0, 95.0, 90.0, 88.0, 95.0, 77.0, 77.0, 77.0, 95.0, 95.0, 93.0, 88.0, 88.0, 88.0, 90.0, 76.0, 76.0, 74.0, 93.0, 93.0, 90.0, 90.0, 90.0, 90.0, 95.0, 88.0, 90.0, 76.0, 76.0, 76.0, 90.0, 88.0, 88.0, 69.0, 76.0, 76.0, 76.0, 71.0, 90.0, 90.0, 88.0, 74.0, 76.0, 76.0, 76.0, 95.0, 88.0, 88.0, 88.0, 90.0, 77.0, 95.0, 95.0, 93.0, 93.0, 93.0, 90.0, 90.0, 90.0, 93.0, 93.0, 91.0, 91.0, 91.0, 95.0, 90.0, 90.0, 93.0, 74.0, 93.0, 95.0, 95.0, 90.0, 70.0, 93.0, 90.0, 95.0, 77.0, 75.0, 93.0, 95.0, 95.0, 95.0, 77.0, 77.0, 88.0, 93.0, 95.0, 70.0, 90.0, 90.0, 90.0, 93.0, 93.0, 95.0, 76.0, 95.0, 86.0, 88.0, 93.0, 77.0, 95.0, 95.0, 90.0, 90.0, 90.0, 93.0, 95.0, 95.0, 95.0, 95.0, 70.0, 69.0, 69.0, 70.0, 86.0, 86.0, 72.0, 72.0, 72.0, 86.0, 86.0, 71.0, 71.0, 76.0, 95.0, 95.0, 93.0, 95.0, 95.0, 95.0, 93.0, 93.0, 93.0, 93.0, 87.0, 88.0, 89.0, 89.0, 89.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.010905659142430215, 3, 0.8415766068525694, 0.6630314469458599)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 77.8009, Accuracy (at final epoch): 5349/10000 (53%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 70.9787, Accuracy (at final epoch): 4820/10000 (48%)\n","\n","Diff counter is 3\n","\n","The shc reinitialization counter is 3\n","\n","Prev accuracy is 54 and max_accur is 53\n","\n","Picked from diff list\n","\n","******************************************************************************\n","The reinitialization counter is 0, changing chromosome\n","\n","Accuracy of this chromosome is 22.900000000000002\n","\n","The current move counter is 2\n","\n","******************************************************************************\n","======================================\n","Stochastic hill-climbing iteration 9.\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 10.7\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 375.5207054615021.\n","=====================================================\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 11.0, 11.0, 11.0, 11.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 6.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 6.0, 6.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 9.0, 9.0, 9.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 6.0, 6.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 9.0, 9.0, 9.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 6.0, 6.0, 6.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 10.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 13.0, 13.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 6.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 13.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 10.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5628935749851716, 0.5486766157530306, 4, 0.99999999999001, 0.25355423980803526)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3958, Accuracy (at final epoch): 974/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.6462, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 1\n","\n","The shc reinitialization counter is 1\n","\n","Prev accuracy is 53 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 10.\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 11.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 11.0\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 11.200000000000001%.\n","Current learning rate: 0.10500000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 11.200000000000001\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 414.41493487358093.\n","=====================================================\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 6.0, 6.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 6.0, 6.0, 6.0, 13.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 9.0, 9.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 9.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 9.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 13.0, 10.0, 10.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 9.0, 9.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 6.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 6.0, 6.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 13.0, 13.0, 13.0, 6.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 9.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 10.0, 10.0, 10.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 9.0, 9.0, 13.0, 13.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 6.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 6.0, 6.0, 6.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 6.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 6.0, 6.0, 6.0, 9.0, 9.0, 9.0, 9.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 6.0, 6.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5628935749851716, 0.5486766157530306, 4, 0.99999999999001, 0.25355423980803526)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.4305, Accuracy (at final epoch): 974/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3864, Accuracy (at final epoch): 1009/10000 (10%)\n","\n","Diff counter is 2\n","\n","The shc reinitialization counter is 2\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 11.\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Current learning rate: 0.11000000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 452.82700395584106.\n","=====================================================\n","======================================\n","Best accuracy so far: 22.900000000000002\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.5628935749851716, 0.5486766157530306, 4, 0.99999999999001, 0.25355423980803526)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.5204, Accuracy (at final epoch): 974/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.4313, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 3\n","\n","The shc reinitialization counter is 3\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n","Picked from diff list\n","\n","******************************************************************************\n","The reinitialization counter is 0, changing chromosome\n","\n","Accuracy of this chromosome is 19.7\n","\n","The current move counter is 3\n","\n","******************************************************************************\n","======================================\n","Stochastic hill-climbing iteration 12.\n","======================================\n","Best accuracy so far: 19.7\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 10.0\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 18.4%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 18.4\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 492.1918203830719.\n","=====================================================\n","======================================\n","Best accuracy so far: 19.7\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[28.999999999999996, 33.0, 21.0, 21.0, 17.0, 17.0, 18.0, 25.0, 34.0, 33.0, 33.0, 33.0, 38.0, 40.0, 24.0, 22.0, 14.000000000000002, 27.0, 30.0, 28.000000000000004, 21.0, 20.0, 33.0, 31.0, 30.0, 23.0, 23.0, 9.0, 10.0, 8.0, 23.0, 20.0, 27.0, 11.0, 6.0, 11.0, 10.0, 25.0, 26.0, 25.0, 26.0, 9.0, 26.0, 25.0, 23.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 13.0, 13.0, 27.0, 27.0, 27.0, 23.0, 24.0, 21.0, 10.0, 21.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 13.0, 13.0, 13.0, 13.0, 13.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.594101635001411, 0.2714056578346386, 6, 0.99999999999001, 0.2204493295277954)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.2440, Accuracy (at final epoch): 2621/10000 (26%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3991, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 10 and max_accur is 26\n","\n","======================================\n","Stochastic hill-climbing iteration 13.\n","======================================\n","Best accuracy so far: 19.7\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 10.7\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 20.4%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 20.4\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 533.4897780418396.\n","=====================================================\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[30.0, 30.0, 21.0, 30.0, 37.0, 39.0, 46.0, 51.0, 51.0, 43.0, 34.0, 38.0, 38.0, 41.0, 49.0, 52.0, 48.0, 45.0, 45.0, 46.0, 47.0, 47.0, 38.0, 45.0, 42.0, 52.0, 53.0, 50.0, 54.0, 52.0, 60.0, 52.0, 41.0, 41.0, 39.0, 55.00000000000001, 57.99999999999999, 62.0, 63.0, 63.0, 60.0, 60.0, 61.0, 71.0, 60.0, 65.0, 57.99999999999999, 55.00000000000001, 51.0, 49.0, 42.0, 37.0, 42.0, 55.00000000000001, 55.00000000000001, 65.0, 57.99999999999999, 56.99999999999999, 49.0, 49.0, 48.0, 50.0, 52.0, 51.0, 54.0, 60.0, 62.0, 69.0, 57.99999999999999, 53.0, 51.0, 49.0, 50.0, 52.0, 57.99999999999999, 66.0, 59.0, 55.00000000000001, 60.0, 64.0, 64.0, 63.0, 60.0, 56.00000000000001, 50.0, 53.0, 54.0, 61.0, 59.0, 56.00000000000001, 53.0, 54.0, 57.99999999999999, 63.0, 55.00000000000001, 54.0, 49.0, 52.0, 51.0, 52.0, 54.0, 44.0, 51.0, 56.99999999999999, 60.0, 63.0, 68.0, 63.0, 64.0, 59.0, 55.00000000000001, 57.99999999999999, 60.0, 64.0, 63.0, 60.0, 52.0, 48.0, 47.0, 47.0, 46.0, 48.0, 48.0, 50.0, 48.0, 54.0, 48.0, 48.0, 51.0, 51.0, 48.0, 42.0, 38.0, 38.0, 36.0, 37.0, 37.0, 34.0, 41.0, 43.0, 50.0, 49.0, 52.0, 54.0, 53.0, 53.0, 50.0, 41.0, 44.0, 51.0, 49.0, 39.0, 43.0, 44.0, 41.0, 52.0, 52.0, 56.99999999999999, 54.0, 46.0, 43.0, 42.0, 35.0, 28.999999999999996, 28.000000000000004, 33.0, 34.0, 34.0, 39.0, 45.0, 54.0, 47.0, 47.0, 43.0, 45.0, 47.0, 45.0, 51.0, 51.0, 50.0, 44.0, 42.0, 45.0, 44.0, 28.000000000000004, 31.0, 34.0, 40.0, 38.0, 38.0, 38.0, 48.0, 44.0, 44.0, 48.0, 49.0, 46.0, 46.0, 45.0, 47.0, 49.0, 28.999999999999996, 19.0, 28.999999999999996, 27.0, 26.0, 30.0, 39.0, 38.0, 44.0, 44.0, 43.0, 44.0, 40.0, 36.0, 36.0, 39.0, 38.0, 37.0, 38.0, 40.0, 40.0, 40.0, 39.0, 47.0, 47.0, 47.0, 46.0, 44.0, 42.0, 41.0, 47.0, 39.0, 40.0, 34.0, 34.0, 34.0, 35.0, 33.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 33.0, 33.0, 26.0, 28.000000000000004, 26.0, 26.0, 24.0, 24.0, 28.999999999999996, 28.000000000000004, 27.0, 35.0, 35.0, 35.0, 36.0, 31.0, 32.0, 30.0, 32.0, 32.0, 23.0, 24.0, 27.0, 28.999999999999996, 28.999999999999996, 31.0, 34.0, 36.0, 36.0, 36.0, 35.0, 36.0, 36.0, 34.0, 34.0, 27.0, 27.0, 27.0, 34.0, 34.0, 33.0, 33.0, 25.0, 33.0, 40.0, 37.0, 30.0, 30.0, 28.999999999999996, 28.999999999999996, 26.0, 28.000000000000004, 28.000000000000004, 27.0, 27.0, 27.0, 25.0, 25.0, 21.0, 21.0, 21.0, 21.0, 21.0, 19.0, 25.0, 25.0, 26.0, 26.0, 15.0, 15.0, 24.0, 24.0, 23.0, 28.000000000000004, 20.0, 25.0, 25.0, 25.0, 24.0, 24.0, 20.0, 20.0, 20.0, 24.0, 31.0, 28.000000000000004, 26.0, 26.0, 26.0, 26.0, 26.0, 18.0, 19.0, 23.0, 23.0, 18.0, 18.0, 27.0, 27.0, 21.0, 20.0, 20.0, 20.0, 22.0, 17.0, 6.0, 5.0, 6.0, 6.0, 15.0, 21.0, 14.000000000000002, 20.0, 18.0, 22.0, 27.0, 30.0, 32.0, 28.000000000000004, 24.0, 24.0, 24.0, 24.0, 23.0, 28.000000000000004, 27.0, 27.0, 28.000000000000004, 28.000000000000004, 22.0, 16.0, 16.0, 16.0, 17.0, 20.0, 20.0, 22.0, 22.0, 27.0, 27.0, 22.0, 14.000000000000002, 14.000000000000002, 30.0, 30.0, 20.0, 18.0, 18.0, 7.000000000000001, 8.0, 22.0, 31.0, 31.0, 28.999999999999996, 24.0, 24.0, 24.0, 28.999999999999996, 26.0, 15.0, 14.000000000000002, 23.0, 18.0, 18.0, 23.0, 23.0, 19.0, 18.0, 18.0, 16.0, 19.0, 10.0, 20.0, 20.0, 20.0, 24.0, 13.0, 13.0, 24.0, 23.0, 19.0, 23.0, 26.0, 24.0, 18.0, 18.0, 17.0, 17.0, 18.0, 20.0, 19.0, 22.0, 18.0, 18.0, 16.0, 17.0, 19.0, 21.0, 20.0, 18.0, 18.0, 18.0, 18.0, 26.0, 28.000000000000004, 22.0, 21.0, 21.0, 21.0, 26.0, 22.0, 22.0, 22.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 16.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 21.0, 21.0, 21.0, 17.0, 17.0, 12.0, 12.0, 2.0, 2.0, 13.0, 13.0, 23.0, 9.0, 9.0, 9.0, 9.0, 18.0, 18.0, 18.0, 18.0, 23.0, 28.000000000000004, 28.000000000000004, 23.0, 23.0, 22.0, 27.0, 27.0, 21.0, 16.0, 16.0, 16.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 18.0, 18.0, 12.0, 12.0, 12.0, 12.0, 8.0, 8.0, 22.0, 22.0, 14.000000000000002, 14.000000000000002, 20.0, 20.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 13.0, 13.0, 13.0, 15.0, 22.0, 22.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 17.0, 22.0, 22.0, 22.0, 28.000000000000004, 27.0, 27.0, 8.0, 8.0, 8.0, 8.0, 22.0, 27.0, 26.0, 26.0, 10.0, 10.0, 19.0, 19.0, 19.0, 19.0, 20.0, 17.0, 17.0, 17.0, 17.0, 17.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 6.0, 6.0, 5.0, 5.0, 11.0, 21.0, 21.0, 21.0, 22.0, 24.0, 12.0, 13.0, 13.0, 13.0, 13.0, 16.0, 16.0, 11.0, 11.0, 12.0, 14.000000000000002, 14.000000000000002, 13.0, 13.0, 11.0, 18.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 12.0, 12.0, 21.0, 17.0, 17.0, 17.0, 18.0, 19.0, 19.0, 19.0, 10.0, 10.0, 10.0, 18.0, 18.0, 22.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 21.0, 21.0, 21.0, 23.0, 23.0, 20.0, 20.0, 20.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 18.0, 18.0, 15.0, 16.0, 16.0, 20.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 15.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 21.0, 21.0, 12.0, 12.0, 21.0, 26.0, 4.0, 13.0, 13.0, 5.0, 5.0, 19.0, 24.0, 24.0, 24.0, 24.0, 24.0, 19.0, 18.0, 18.0, 23.0, 23.0, 23.0, 23.0, 23.0, 9.0, 9.0, 9.0, 26.0, 28.999999999999996, 23.0, 24.0, 26.0, 25.0, 25.0, 19.0, 19.0, 19.0, 19.0, 22.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 18.0, 18.0, 19.0, 19.0, 18.0, 20.0, 20.0, 22.0, 21.0, 8.0, 19.0, 23.0, 21.0, 22.0, 26.0, 25.0, 24.0, 23.0, 22.0, 20.0, 18.0, 18.0, 20.0, 20.0, 11.0, 11.0, 9.0, 9.0, 21.0, 21.0, 21.0, 20.0, 25.0, 25.0, 25.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 21.0, 19.0, 19.0, 19.0, 19.0, 21.0, 22.0, 22.0, 22.0, 21.0, 28.000000000000004, 28.000000000000004, 19.0, 15.0, 13.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 16.0, 16.0, 24.0, 23.0, 24.0, 24.0, 25.0, 25.0, 17.0, 23.0, 23.0, 23.0, 24.0, 10.0, 10.0, 9.0, 9.0, 19.0, 21.0, 21.0, 21.0, 21.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 12.0, 12.0, 23.0, 23.0, 24.0, 22.0, 22.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 16.0, 23.0, 27.0, 27.0, 27.0, 22.0, 8.0, 8.0, 15.0, 16.0, 16.0, 16.0, 21.0, 21.0, 21.0, 21.0, 21.0, 23.0, 23.0, 19.0, 19.0, 19.0, 15.0, 16.0, 16.0, 16.0, 16.0, 24.0, 24.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 19.0, 13.0, 17.0, 17.0, 17.0, 19.0, 19.0, 19.0, 19.0, 19.0, 17.0, 17.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 17.0, 15.0, 15.0, 16.0, 16.0, 16.0, 20.0, 20.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 10.0, 10.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 10.0, 8.0, 24.0, 24.0, 10.0, 9.0, 16.0, 24.0, 24.0, 20.0, 12.0, 16.0, 16.0, 16.0, 18.0, 18.0, 18.0, 17.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 15.0, 15.0, 8.0, 8.0, 9.0, 9.0, 9.0, 8.0, 8.0, 18.0, 16.0, 16.0, 16.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 22.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 21.0, 21.0, 21.0, 32.0, 32.0, 32.0, 32.0, 32.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 22.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 6.0, 6.0, 12.0, 12.0, 10.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 28.000000000000004, 28.999999999999996, 28.999999999999996, 25.0, 25.0, 25.0, 25.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.001, 8, 0.99999999999001, 0.24987499999750126)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3842, Accuracy (at final epoch): 4106/10000 (41%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 82.8533, Accuracy (at final epoch): 2165/10000 (22%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 26 and max_accur is 41\n","\n","======================================\n","Stochastic hill-climbing iteration 14.\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.1\n","\n","***********************************************\n","Best accuracy after differential search: 10.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 575.2989342212677.\n","=====================================================\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[27.0, 27.0, 33.0, 25.0, 25.0, 26.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 24.0, 23.0, 25.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 13.0, 19.0, 19.0, 24.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 33.0, 33.0, 33.0, 33.0, 12.0, 12.0, 12.0, 5.0, 6.0, 6.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 18.0, 18.0, 18.0, 21.0, 21.0, 21.0, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 16.0, 16.0, 22.0, 22.0, 17.0, 17.0, 11.0, 11.0, 11.0, 11.0, 11.0, 16.0, 18.0, 18.0, 19.0, 19.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 31.0, 31.0, 17.0, 13.0, 12.0, 12.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.000000000000002, 19.0, 17.0, 17.0, 17.0, 12.0, 12.0, 23.0, 23.0, 21.0, 21.0, 15.0, 15.0, 18.0, 20.0, 15.0, 15.0, 6.0, 6.0, 20.0, 20.0, 20.0, 24.0, 24.0, 24.0, 24.0, 10.0, 13.0, 6.0, 6.0, 13.0, 13.0, 24.0, 24.0, 26.0, 26.0, 21.0, 21.0, 16.0, 16.0, 12.0, 12.0, 12.0, 12.0, 12.0, 17.0, 17.0, 17.0, 21.0, 21.0, 22.0, 22.0, 22.0, 21.0, 17.0, 17.0, 17.0, 20.0, 20.0, 20.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 17.0, 11.0, 11.0, 11.0, 11.0, 25.0, 25.0, 25.0, 16.0, 16.0, 15.0, 15.0, 9.0, 9.0, 9.0, 20.0, 21.0, 21.0, 25.0, 25.0, 25.0, 31.0, 27.0, 16.0, 25.0, 25.0, 25.0, 25.0, 19.0, 20.0, 20.0, 20.0, 19.0, 19.0, 14.000000000000002, 14.000000000000002, 13.0, 13.0, 21.0, 23.0, 23.0, 23.0, 14.000000000000002, 21.0, 21.0, 23.0, 23.0, 16.0, 16.0, 16.0, 15.0, 16.0, 16.0, 16.0, 24.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 22.0, 24.0, 31.0, 31.0, 20.0, 20.0, 20.0, 18.0, 18.0, 18.0, 15.0, 22.0, 31.0, 31.0, 31.0, 9.0, 9.0, 9.0, 9.0, 9.0, 20.0, 23.0, 19.0, 23.0, 17.0, 17.0, 17.0, 17.0, 19.0, 19.0, 23.0, 25.0, 25.0, 16.0, 16.0, 16.0, 16.0, 18.0, 18.0, 18.0, 12.0, 12.0, 10.0, 10.0, 19.0, 19.0, 19.0, 19.0, 21.0, 21.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 25.0, 21.0, 21.0, 21.0, 28.999999999999996, 31.0, 35.0, 35.0, 30.0, 30.0, 26.0, 25.0, 25.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 12.0, 17.0, 26.0, 26.0, 26.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 25.0, 25.0, 25.0, 10.0, 10.0, 6.0, 6.0, 6.0, 6.0, 15.0, 15.0, 17.0, 18.0, 22.0, 22.0, 22.0, 22.0, 16.0, 16.0, 19.0, 19.0, 19.0, 25.0, 19.0, 19.0, 23.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 28.999999999999996, 28.000000000000004, 22.0, 22.0, 14.000000000000002, 14.000000000000002, 12.0, 12.0, 20.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 18.0, 16.0, 16.0, 16.0, 16.0, 22.0, 22.0, 15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 15.0, 9.0, 16.0, 16.0, 17.0, 23.0, 23.0, 23.0, 27.0, 27.0, 28.000000000000004, 35.0, 35.0, 35.0, 35.0, 20.0, 20.0, 20.0, 20.0, 20.0, 25.0, 25.0, 18.0, 19.0, 28.000000000000004, 24.0, 19.0, 8.0, 9.0, 9.0, 9.0, 19.0, 19.0, 20.0, 20.0, 24.0, 24.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 24.0, 24.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 16.0, 16.0, 16.0, 13.0, 13.0, 12.0, 14.000000000000002, 9.0, 9.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 9.0, 18.0, 18.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 19.0, 19.0, 16.0, 16.0, 20.0, 20.0, 20.0, 20.0, 16.0, 16.0, 16.0, 22.0, 26.0, 26.0, 22.0, 22.0, 22.0, 21.0, 22.0, 18.0, 7.000000000000001, 7.000000000000001, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 14.000000000000002, 14.000000000000002, 5.0, 5.0, 5.0, 5.0, 5.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 23.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 17.0, 17.0, 7.000000000000001, 7.000000000000001, 8.0, 13.0, 13.0, 13.0, 13.0, 13.0, 8.0, 8.0, 9.0, 9.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 9.0, 9.0, 9.0, 9.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 21.0, 20.0, 27.0, 27.0, 27.0, 27.0, 18.0, 18.0, 24.0, 24.0, 24.0, 24.0, 27.0, 22.0, 22.0, 22.0, 16.0, 16.0, 16.0, 16.0, 16.0, 8.0, 8.0, 11.0, 11.0, 21.0, 14.000000000000002, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 19.0, 19.0, 19.0, 27.0, 27.0, 13.0, 13.0, 6.0, 6.0, 6.0, 8.0, 8.0, 22.0, 22.0, 22.0, 22.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 30.0, 21.0, 21.0, 21.0, 21.0, 21.0, 23.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 21.0, 18.0, 18.0, 18.0, 18.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 27.0, 33.0, 33.0, 33.0, 26.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 19.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 17.0, 17.0, 17.0, 17.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 16.0, 16.0, 16.0, 7.000000000000001, 7.000000000000001, 6.0, 21.0, 15.0, 15.0, 15.0, 15.0, 15.0, 11.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 13.0, 13.0, 13.0, 8.0, 1.0, 1.0, 1.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 17.0, 11.0, 20.0, 20.0, 21.0, 21.0, 27.0, 27.0, 30.0, 16.0, 16.0, 16.0, 13.0, 2.0, 2.0, 2.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 9.0, 9.0, 9.0, 9.0, 20.0, 20.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 10.0, 10.0, 18.0, 18.0, 18.0, 18.0, 18.0, 24.0, 24.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 26.0, 23.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 23.0, 23.0, 23.0, 23.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 23.0, 17.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 18.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 22.0, 15.0, 15.0, 15.0, 15.0, 15.0, 9.0, 15.0, 18.0, 19.0, 19.0, 19.0, 21.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.000000000000004, 19.0, 19.0, 19.0, 28.999999999999996, 25.0, 18.0, 18.0, 18.0, 18.0, 17.0, 23.0, 23.0, 23.0, 23.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 17.0, 17.0, 17.0, 17.0, 23.0, 24.0, 24.0, 20.0, 20.0, 20.0, 22.0, 22.0, 26.0, 30.0, 30.0, 30.0, 30.0, 30.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 26.0, 26.0, 26.0, 20.0, 20.0, 20.0, 20.0, 26.0, 26.0, 26.0, 30.0, 30.0, 24.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 30.0, 30.0, 30.0, 30.0, 30.0, 28.000000000000004, 20.0, 20.0, 20.0, 20.0, 26.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 18.0, 18.0, 21.0, 21.0, 21.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 20.0, 20.0, 20.0, 21.0, 21.0, 30.0, 30.0, 24.0, 24.0, 24.0, 24.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 24.0, 13.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 12.0, 12.0, 23.0, 23.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 27.0, 27.0, 27.0, 27.0, 20.0, 20.0, 20.0, 16.0, 16.0, 16.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 15.0, 15.0, 15.0, 14.000000000000002, 16.0, 16.0, 16.0, 16.0, 16.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.001, 8, 0.99999999999001, 0.24987499999750126)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 50.0375, Accuracy (at final epoch): 2234/10000 (22%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 113.3394, Accuracy (at final epoch): 1794/10000 (18%)\n","\n","Diff counter is 1\n","\n","The shc reinitialization counter is 1\n","\n","Prev accuracy is 41 and max_accur is 22\n","\n","======================================\n","Stochastic hill-climbing iteration 15.\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Current learning rate: 0.10500000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 617.9831643104553.\n","=====================================================\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[21.0, 13.0, 18.0, 18.0, 22.0, 26.0, 26.0, 17.0, 17.0, 20.0, 20.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 21.0, 23.0, 23.0, 25.0, 28.999999999999996, 28.999999999999996, 16.0, 16.0, 16.0, 16.0, 34.0, 34.0, 27.0, 27.0, 21.0, 21.0, 21.0, 28.000000000000004, 30.0, 25.0, 25.0, 25.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 21.0, 21.0, 21.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 30.0, 26.0, 26.0, 26.0, 31.0, 31.0, 31.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 21.0, 28.000000000000004, 34.0, 20.0, 20.0, 20.0, 17.0, 17.0, 17.0, 30.0, 30.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 19.0, 19.0, 19.0, 21.0, 21.0, 21.0, 23.0, 14.000000000000002, 14.000000000000002, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 12.0, 13.0, 13.0, 13.0, 13.0, 12.0, 6.0, 6.0, 6.0, 6.0, 21.0, 23.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 23.0, 8.0, 8.0, 8.0, 7.000000000000001, 7.000000000000001, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 10.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 27.0, 27.0, 27.0, 27.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 13.0, 9.0, 9.0, 18.0, 18.0, 18.0, 18.0, 18.0, 20.0, 20.0, 20.0, 20.0, 26.0, 22.0, 22.0, 18.0, 18.0, 25.0, 20.0, 20.0, 20.0, 24.0, 24.0, 24.0, 27.0, 27.0, 20.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 11.0, 11.0, 17.0, 20.0, 20.0, 20.0, 10.0, 9.0, 15.0, 28.999999999999996, 28.999999999999996, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.999999999999996, 28.999999999999996, 23.0, 23.0, 23.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 16.0, 16.0, 16.0, 16.0, 22.0, 22.0, 26.0, 26.0, 26.0, 21.0, 21.0, 21.0, 21.0, 15.0, 15.0, 15.0, 20.0, 20.0, 20.0, 16.0, 16.0, 16.0, 16.0, 22.0, 22.0, 18.0, 18.0, 15.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 4.0, 4.0, 7.000000000000001, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 26.0, 26.0, 26.0, 26.0, 30.0, 30.0, 30.0, 30.0, 30.0, 25.0, 22.0, 21.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 10.0, 10.0, 9.0, 9.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 5.0, 5.0, 5.0, 5.0, 23.0, 23.0, 23.0, 19.0, 19.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 18.0, 21.0, 13.0, 13.0, 13.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 19.0, 19.0, 19.0, 19.0, 19.0, 21.0, 21.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 19.0, 20.0, 19.0, 19.0, 19.0, 19.0, 16.0, 16.0, 16.0, 22.0, 22.0, 22.0, 22.0, 22.0, 20.0, 20.0, 23.0, 17.0, 17.0, 17.0, 17.0, 17.0, 11.0, 11.0, 11.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 7.000000000000001, 16.0, 16.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 21.0, 21.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 18.0, 21.0, 21.0, 21.0, 21.0, 11.0, 15.0, 15.0, 15.0, 15.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 15.0, 15.0, 15.0, 28.999999999999996, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 26.0, 26.0, 26.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.000000000000002, 7.000000000000001, 12.0, 12.0, 12.0, 12.0, 10.0, 21.0, 21.0, 21.0, 21.0, 27.0, 27.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 10.0, 10.0, 10.0, 10.0, 16.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 15.0, 13.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 21.0, 20.0, 20.0, 20.0, 20.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 16.0, 16.0, 7.000000000000001, 7.000000000000001, 13.0, 13.0, 13.0, 13.0, 13.0, 18.0, 18.0, 18.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 26.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 20.0, 23.0, 23.0, 23.0, 23.0, 9.0, 9.0, 9.0, 9.0, 9.0, 11.0, 19.0, 19.0, 19.0, 19.0, 19.0, 15.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 19.0, 19.0, 23.0, 16.0, 16.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 18.0, 18.0, 18.0, 18.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 14.000000000000002, 14.000000000000002, 14.000000000000002, 14.000000000000002, 20.0, 34.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 16.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 9.0, 23.0, 19.0, 19.0, 19.0, 25.0, 25.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 23.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 23.0, 23.0, 17.0, 17.0, 23.0, 23.0, 26.0, 26.0, 26.0, 26.0, 20.0, 20.0, 20.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 11.0, 19.0, 19.0, 19.0, 19.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 22.0, 22.0, 22.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 20.0, 20.0, 22.0, 22.0, 25.0, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 28.999999999999996, 25.0, 25.0, 24.0, 24.0, 24.0, 22.0, 27.0, 21.0, 21.0, 21.0, 21.0, 23.0, 23.0, 18.0, 18.0, 24.0, 24.0, 24.0, 24.0, 24.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 23.0, 23.0, 23.0, 23.0, 27.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 27.0, 27.0, 27.0, 27.0, 20.0, 14.000000000000002, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 30.0, 19.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 14.000000000000002, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.000000000000002, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 20.0, 20.0, 20.0, 20.0, 17.0, 17.0, 17.0, 23.0, 23.0, 23.0, 13.0, 13.0, 13.0, 13.0, 5.0, 5.0, 5.0, 5.0, 5.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 16.0, 15.0, 1.0, 14.000000000000002, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 14.000000000000002, 13.0, 13.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 16.0, 16.0, 16.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 17.0, 17.0, 17.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.000000000000002, 14.000000000000002, 24.0, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 28.000000000000004, 27.0, 21.0, 21.0, 17.0, 17.0, 20.0, 20.0, 20.0, 20.0, 24.0, 19.0, 19.0, 19.0, 19.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 9.0, 9.0, 9.0, 9.0, 14.000000000000002, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 14.000000000000002, 19.0, 19.0, 19.0, 19.0, 19.0, 14.000000000000002, 15.0, 15.0, 15.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 19.0, 19.0, 22.0, 22.0, 22.0, 19.0, 19.0, 19.0, 19.0, 21.0, 18.0, 13.0, 13.0, 13.0, 13.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.99999999998001, 0.001, 8, 0.99999999999001, 0.24987499999750126)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 126.2378, Accuracy (at final epoch): 2263/10000 (23%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 191.5593, Accuracy (at final epoch): 1569/10000 (16%)\n","\n","Diff counter is 2\n","\n","The shc reinitialization counter is 2\n","\n","Prev accuracy is 22 and max_accur is 22\n","\n","======================================\n","Stochastic hill-climbing iteration 16.\n","======================================\n","Best accuracy so far: 20.4\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 14.099999999999998%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 30.099999999999998%.\n","***********************************************\n","Best accuracy after random mutation: 30.099999999999998\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Current learning rate: 0.11000000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 10.9\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 660.2250151634216.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 24.0, 24.0, 28.999999999999996, 33.0, 31.0, 20.0, 34.0, 14.000000000000002, 28.999999999999996, 39.0, 28.999999999999996, 31.0, 38.0, 31.0, 31.0, 33.0, 30.0, 34.0, 37.0, 38.0, 33.0, 24.0, 24.0, 24.0, 21.0, 23.0, 10.0, 3.0, 20.0, 20.0, 20.0, 20.0, 19.0, 9.0, 13.0, 20.0, 9.0, 6.0, 7.000000000000001, 22.0, 17.0, 14.000000000000002, 9.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 5.0, 11.0, 11.0, 11.0, 21.0, 17.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 9.0, 9.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 11.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.8136420958757424, 0.4533660501012896, 10, 0.99999999999001, 0.13602760457744528)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.9046, Accuracy (at final epoch): 2477/10000 (25%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3508, Accuracy (at final epoch): 974/10000 (10%)\n","\n","Diff counter is 0\n","\n","The shc reinitialization counter is 0\n","\n","Prev accuracy is 22 and max_accur is 24\n","\n","======================================\n","Stochastic hill-climbing iteration 17.\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 18.099999999999998%.\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 18.099999999999998\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 19.6%.\n","Best validation accuracy: 25.3%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 22.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 11.3%.\n","Current learning rate: 0.11000000000000001\n","\n","***********************************************\n","Best accuracy after differential search: 25.3\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 691.6600844860077.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 13.0, 13.0, 13.0, 13.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 11.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.8136420958757424, 0.4533660501012896, 10, 0.99999999999001, 0.13602760457744528)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3736, Accuracy (at final epoch): 974/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3583, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 1\n","\n","The shc reinitialization counter is 1\n","\n","Prev accuracy is 24 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 18.\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Best validation accuracy: 10.0%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","***********************************************\n","Best accuracy after random mutation: 10.9\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.11500000000000002\n","\n","***********************************************\n","Best accuracy after differential search: 10.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 723.1183197498322.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.8136420958757424, 0.4533660501012896, 10, 0.99999999999001, 0.13602760457744528)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3631, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Model at the end of training: \n","\n","Test set: Average loss: 2.3943, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 2\n","\n","The shc reinitialization counter is 2\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n","======================================\n","Stochastic hill-climbing iteration 19.\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 18.6%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 18.4%.\n","Best validation accuracy: 10.9%.\n","Best validation accuracy: 9.8%.\n","***********************************************\n","Best accuracy after random mutation: 18.6\n","***********************************************\n","\n","\n","***** Differential Search *********************\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 10.7%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 9.8%.\n","Best validation accuracy: 10.7%.\n","Current learning rate: 0.12000000000000002\n","\n","***********************************************\n","Best accuracy after differential search: 10.7\n","***********************************************\n","=====================================================\n","Architectural optimization total time: 754.6935298442841.\n","=====================================================\n","======================================\n","Best accuracy so far: 30.099999999999998\n","======================================\n","Computing the final test ...\n","=====================================\n","Training accuracies\n","=====================================\n","[20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0]\n","=====================================\n","Best training parameters\n","=====================================\n","(1.8136420958757424, 0.4533660501012896, 10, 0.99999999999001, 0.13602760457744528)\n","=====================================\n","Test accuracies\n","=====================================\n","Model with best validation accuracy: \n","\n","Test set: Average loss: 2.3906, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Model at the end of training: \n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","100%|██████████| 10/10 [22:34<00:00, 135.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 2.3741, Accuracy (at final epoch): 1028/10000 (10%)\n","\n","Diff counter is 3\n","\n","The shc reinitialization counter is 3\n","\n","Prev accuracy is 10 and max_accur is 10\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kBTp6w0Nzd_X"},"source":["## Display Graph, Write to File"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vXZ2hP43nq_-","outputId":"bf5bad55-852a-43b5-d4f3-58ea5ec1f189","executionInfo":{"status":"ok","timestamp":1586245024388,"user_tz":-480,"elapsed":1365079,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"source":["# Update file with final metrics\n","path = '/content/gdrive/My Drive/Chromosome Saves/'\n","update_file_with_metrics(path, iterations+1, evaluation_counter, total_time_taken, y_axis_plot, meta, diff_lr_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","Mean accuracy of models are 66.4\n","Mean variance of results is 355.43999999999994\n","Standard deviation of results is 18.853116453255147\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZBmEDFd2ZkT_","outputId":"a50002de-aa11-47e1-de58-e9d8ab77fd1d","executionInfo":{"status":"ok","timestamp":1586246632038,"user_tz":-480,"elapsed":3362,"user":{"displayName":"Jiachenn CJC","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPmJByrMnLm4oklazFjDO806815g1QjwthSVtpJA=s64","userId":"14197129540936949678"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["# Plot bar graph, line graph \n","plot_bar_2(x_axis_plot, y_axis_plot)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mean accuracy of models are 66.4\n","Mean variance of results is 355.43999999999994\n","Standard deviation of results is 18.853116453255147\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEjCAYAAAA1ymrVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMfglqTH/H2cthgc9+TDMAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FCl2YedlFrAM"},"source":["## Save chromosome"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OAjk-c31Fs9-","colab":{}},"source":["# --- Saving the best chromosome as a csv file\n","# if args['save_best_chrom']:\n","#     print('Saving the best chromosome in the root directory (My Drive) ...')\n","#     drive.mount('/content/gdrive/')\n","\n","#     def get_date_time_str():\n","#         now = datetime.now() # current date and time\n","#         return now.strftime(\"%d%m%Y_%H%M\") \n","\n","#     # Create filename\n","#     path = '/content/gdrive/My Drive/Chromosome Saves/'\n","#     filename = 'chrom_acc'+ str(max_accur)\n","# #   filename = 'chrom_' + get_date_time_str() + version + str(max_accur)\n","#     savetxt(path+filename, best_chromosome, delimiter=',')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0D9yZKj6sdiY"},"source":["# Glossary\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pQqL6suyshYz"},"source":["\n","\n","1.   Chromosome\n","    - A set of parameters that define a proposed solution to a problem that an algorithm is trying to solve.\n","    - e.g Travelling salesman problem: A chromosome might be the list of ordered cities to try. e.g [B,C,A,E,D]\n","\n"]}]}